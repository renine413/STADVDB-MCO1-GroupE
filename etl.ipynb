{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b08927",
   "metadata": {},
   "source": [
    "# ETL Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5dff2",
   "metadata": {},
   "source": [
    "## 1. Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a45fc",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29bb4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import shutil \n",
    "import zipfile\n",
    "import requests\n",
    "import tempfile\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d276c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading hopesb/student-depression-dataset\n",
      " -> returned: C:\\Users\\fonte\\.cache\\kagglehub\\datasets\\hopesb\\student-depression-dataset\\versions\\1\n",
      "Downloading adilshamim8/social-media-addiction-vs-relationships\n",
      " -> returned: C:\\Users\\fonte\\.cache\\kagglehub\\datasets\\adilshamim8\\social-media-addiction-vs-relationships\\versions\\3\n",
      "Downloading mahmoudelhemaly/students-grading-dataset\n",
      " -> returned: C:\\Users\\fonte\\.cache\\kagglehub\\datasets\\mahmoudelhemaly\\students-grading-dataset\\versions\\5\n",
      "Downloading danishshaikh18/required-datasets\n",
      " -> returned: C:\\Users\\fonte\\.cache\\kagglehub\\datasets\\danishshaikh18\\required-datasets\\versions\\1\n",
      "Fetching CDC JSON...\n",
      "Preserving correct dataset: kaggle-student-depression-dataset-student-depression-dataset.csv\n",
      "Datasets now: ['cdc-indicators-of-anxiety-or-depression.json', 'kaggle-student-depression-dataset.csv', 'kaggle-student-mental-health-crisis-after-covid19-final.xlsx', 'kaggle-students-social-media-addiction.csv', 'mendeley-phq9-student-depression-dataset.csv']\n"
     ]
    }
   ],
   "source": [
    "OUT = Path(\"datasets\")\n",
    "OUT.mkdir(exist_ok=True)\n",
    "\n",
    "kaggle_list = {\n",
    "    \"hopesb/student-depression-dataset\": \"kaggle-student-depression-dataset\",\n",
    "    \"adilshamim8/social-media-addiction-vs-relationships\": \"kaggle-students-social-media-addiction\",\n",
    "    \"mahmoudelhemaly/students-grading-dataset\": \"kaggle-student-performance-and-behavior-dataset\",\n",
    "    \"danishshaikh18/required-datasets\": \"kaggle-student-mental-health-crisis-after-covid19-final\"\n",
    "}\n",
    "\n",
    "def safe_copy(src, dst):\n",
    "    dst.parent.mkdir(exist_ok=True, parents=True)\n",
    "    if not dst.exists():\n",
    "        shutil.copy2(src, dst)\n",
    "\n",
    "for ds, prefix in kaggle_list.items():\n",
    "    try:\n",
    "        print(\"Downloading\", ds)\n",
    "        path = Path(kagglehub.dataset_download(ds)) \n",
    "        print(\" -> returned:\", path)\n",
    "\n",
    "        if path.suffix == \".zip\":\n",
    "            with zipfile.ZipFile(path, \"r\") as z:\n",
    "                extract_dir = OUT / prefix\n",
    "                extract_dir.mkdir(exist_ok=True)\n",
    "                z.extractall(extract_dir)\n",
    "                print(\"Extracted:\", extract_dir)\n",
    "            for f in extract_dir.rglob(\"*\"):\n",
    "                if f.suffix.lower() in [\".csv\", \".xlsx\"]:\n",
    "                    new_name = f\"{prefix}{f.suffix.lower()}\"\n",
    "                    safe_copy(f, OUT / new_name)\n",
    "            for f in extract_dir.rglob(\"*.json\"):\n",
    "                new_name = f\"{prefix}.json\"\n",
    "                safe_copy(f, OUT / new_name)\n",
    "\n",
    "        elif path.is_dir():\n",
    "            for f in path.rglob(\"*\"):\n",
    "                if f.suffix.lower() in [\".csv\", \".xlsx\"]:\n",
    "                    new_name = f\"{prefix}-{f.name.lower().replace(' ', '-').replace('_', '-')}\"\n",
    "                    safe_copy(f, OUT / new_name)\n",
    "            for f in path.rglob(\"*.json\"):\n",
    "                new_name = f\"{prefix}.json\"\n",
    "                safe_copy(f, OUT / new_name)\n",
    "\n",
    "        elif path.exists() and path.suffix != \".zip\":\n",
    "            safe_copy(path, OUT / f\"{prefix}-{path.name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Download failed for\", ds, \":\", e)\n",
    "    time.sleep(1)\n",
    "\n",
    "try:\n",
    "    cdc_url = \"https://data.cdc.gov/resource/8pt5-q6wp.json\"\n",
    "    print(\"Fetching CDC JSON...\")\n",
    "    r = requests.get(cdc_url, timeout=30)\n",
    "    if r.ok:\n",
    "        (OUT / \"cdc-indicators-of-anxiety-or-depression.json\").write_bytes(r.content)\n",
    "except Exception as e:\n",
    "    print(\"CDC fetch error:\", e)\n",
    "\n",
    "\n",
    "good_path = OUT / \"kaggle-student-depression-dataset-student-depression-dataset.csv\"\n",
    "final_path = OUT / \"kaggle-student-depression-dataset.csv\"\n",
    "if good_path.exists():\n",
    "    print(\"Preserving correct dataset:\", good_path.name)\n",
    "    if final_path.exists():\n",
    "        print(\"Existing corrupt file detected, removing:\", final_path.name)\n",
    "        final_path.unlink()\n",
    "    good_path.rename(final_path)\n",
    "\n",
    "mapping = {\n",
    "    \"phq\": \"mendeley-phq9-student-depression-dataset.csv\",\n",
    "    \"student-depression\": \"kaggle-student-depression-dataset.csv\",\n",
    "    \"social-media\": \"kaggle-students-social-media-addiction.csv\",\n",
    "    \"addiction\": \"kaggle-students-social-media-addiction.csv\",\n",
    "    \"mental-health-crisis\": \"kaggle-student-mental-health-crisis-after-covid19-final.xlsx\",\n",
    "    \"performance\": \"kaggle-student-performance-and-behavior-dataset.json\",\n",
    "    \"cdc\": \"cdc-indicators-of-anxiety-or-depression.json\"\n",
    "}\n",
    "\n",
    "deletions = {\n",
    "    \"student_depression_dataset.xlsx\",\n",
    "    \"students performance dataset.csv\",\n",
    "    \"students_grading_dataset_biased.csv\",\n",
    "    \"students_grading_dataset_biased.json\",\n",
    "    \"metadata.xlsx\",\n",
    "    \"kaggle-student-performance-and-behavior-dataset.json\"\n",
    "}\n",
    "\n",
    "for f in OUT.iterdir():\n",
    "    if not f.is_file():\n",
    "        continue\n",
    "    ln = f.name.lower()\n",
    "    if ln in deletions:\n",
    "        f.unlink(missing_ok=True)\n",
    "        continue\n",
    "    for key, tgt in mapping.items():\n",
    "        if key in ln:\n",
    "            tgtp = OUT / tgt\n",
    "            if tgtp.exists() and f.resolve() == tgtp.resolve():\n",
    "                break\n",
    "            if tgtp.exists() and tgtp == final_path:\n",
    "                continue\n",
    "            tgtp.unlink(missing_ok=True)\n",
    "            try:\n",
    "                f.replace(tgtp)\n",
    "            except Exception:\n",
    "                safe_copy(f, tgtp)\n",
    "                f.unlink(missing_ok=True)\n",
    "            break\n",
    "\n",
    "print(\"Datasets now:\", [p.name for p in sorted(OUT.iterdir())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e134c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Kaggle dataset: mahmoudelhemaly/students-grading-dataset\n",
      " -> returned: C:\\Users\\fonte\\.cache\\kagglehub\\datasets\\mahmoudelhemaly\\students-grading-dataset\\versions\\5\n",
      "Validated/fixed JSON saved as: datasets\\kaggle-student-performance-and-behavior-dataset.json\n",
      "Final dataset location: datasets\\kaggle-student-performance-and-behavior-dataset.json\n"
     ]
    }
   ],
   "source": [
    "OUT = Path(\"datasets\")\n",
    "OUT.mkdir(exist_ok=True)\n",
    "\n",
    "KAGGLE_DATASET = \"mahmoudelhemaly/students-grading-dataset\"\n",
    "PREFIX = \"kaggle-student-performance-and-behavior-dataset\"\n",
    "\n",
    "def write_atomic_json(obj, dst: Path):\n",
    "    dst.parent.mkdir(exist_ok=True, parents=True)\n",
    "    tmp = None\n",
    "    try:\n",
    "        fd, tmp = tempfile.mkstemp(suffix=\".json\", dir=str(dst.parent))\n",
    "        with os.fdopen(fd, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "        os.replace(tmp, str(dst))\n",
    "    finally:\n",
    "        if tmp and os.path.exists(tmp):\n",
    "            try:\n",
    "                os.remove(tmp)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "def validate_and_fix_json(src: Path, dst: Path) -> bool:\n",
    "    try:\n",
    "        text = src.read_text(encoding=\"utf-8\", errors=\"replace\").strip()\n",
    "    except Exception as e:\n",
    "        print(\"Failed to read JSON candidate:\", src, \":\", e)\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        write_atomic_json(obj, dst)\n",
    "        return True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        import pandas as _pd\n",
    "        try:\n",
    "            df = _pd.read_json(src, lines=True)\n",
    "            recs = df.to_dict(orient=\"records\")\n",
    "            write_atomic_json(recs, dst)\n",
    "            return True\n",
    "        except Exception:\n",
    "            pass\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    objs = []\n",
    "    success = False\n",
    "    if lines:\n",
    "        for ln in lines:\n",
    "            try:\n",
    "                objs.append(json.loads(ln))\n",
    "            except Exception:\n",
    "                objs = []\n",
    "                break\n",
    "        if objs:\n",
    "            write_atomic_json(objs, dst)\n",
    "            return True\n",
    "\n",
    "    try:\n",
    "        parts = re.split(r'}\\s*{', text)\n",
    "        if len(parts) > 1:\n",
    "            reconstructed = []\n",
    "            for i, p in enumerate(parts):\n",
    "                s = p\n",
    "                if i != 0:\n",
    "                    s = \"{\" + s\n",
    "                if i != len(parts) - 1:\n",
    "                    s = s + \"}\"\n",
    "                try:\n",
    "                    reconstructed.append(json.loads(s))\n",
    "                except Exception:\n",
    "                    reconstructed = []\n",
    "                    break\n",
    "            if reconstructed:\n",
    "                write_atomic_json(reconstructed, dst)\n",
    "                return True\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return False\n",
    "\n",
    "try:\n",
    "    print(\"Downloading Kaggle dataset:\", KAGGLE_DATASET)\n",
    "    path = Path(kagglehub.dataset_download(KAGGLE_DATASET))\n",
    "    print(\" -> returned:\", path)\n",
    "\n",
    "    final_path = OUT / f\"{PREFIX}.json\"\n",
    "\n",
    "    if path.suffix.lower() == \".zip\":\n",
    "        with zipfile.ZipFile(path, \"r\") as z:\n",
    "            extract_dir = OUT / PREFIX\n",
    "            extract_dir.mkdir(exist_ok=True)\n",
    "            z.extractall(extract_dir)\n",
    "            print(\"Extracted:\", extract_dir)\n",
    "\n",
    "        for f in extract_dir.rglob(\"*.json\"):\n",
    "            ok = validate_and_fix_json(f, final_path)\n",
    "            if ok:\n",
    "                print(\"Validated/fixed JSON saved as:\", final_path)\n",
    "            else:\n",
    "                print(\"Warning: could not parse JSON. Falling back to raw copy:\", f)\n",
    "                safe_copy(f, final_path)\n",
    "            break\n",
    "\n",
    "    elif path.is_dir():\n",
    "        for f in path.rglob(\"*.json\"):\n",
    "            ok = validate_and_fix_json(f, final_path)\n",
    "            if ok:\n",
    "                print(\"Validated/fixed JSON saved as:\", final_path)\n",
    "            else:\n",
    "                print(\"Warning: could not parse JSON. Falling back to raw copy:\", f)\n",
    "                safe_copy(f, final_path)\n",
    "            break\n",
    "\n",
    "    elif path.exists() and path.suffix.lower() == \".json\":\n",
    "        ok = validate_and_fix_json(path, final_path)\n",
    "        if ok:\n",
    "            print(\"Validated/fixed JSON saved as:\", final_path)\n",
    "        else:\n",
    "            print(\"Warning: could not parse JSON. Falling back to raw copy:\", path)\n",
    "            safe_copy(path, final_path)\n",
    "\n",
    "    else:\n",
    "        print(\"No JSON file found in the downloaded dataset.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Download or extraction failed:\", e)\n",
    "\n",
    "print(\"Final dataset location:\", final_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4124f",
   "metadata": {},
   "source": [
    "Read datasets:\n",
    "1. Indicators of Anxiety or Depression Based on Reported Frequency of Symptoms During Last 7 Days\n",
    "2. Student Depression Dataset\n",
    "3. Student Mental Health Crisis After COVID-19\n",
    "4. Student Performance and Behavior Dataset\n",
    "5. Students Social Media Addiction Dataset\n",
    "6. PHQ-9 Student Depression Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6804be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json(\"datasets/cdc-indicators-of-anxiety-or-depression.json\")\n",
    "df2 = pd.read_csv(\"datasets/kaggle-student-depression-dataset.csv\")\n",
    "df3 = pd.read_excel(\"datasets/kaggle-student-mental-health-crisis-after-covid19-final.xlsx\")\n",
    "df4 = pd.read_json(\"datasets/kaggle-student-performance-and-behavior-dataset.json\")\n",
    "df5 = pd.read_csv(\"datasets/kaggle-students-social-media-addiction.csv\")\n",
    "df6 = pd.read_csv(\"datasets/mendeley-phq9-student-depression-dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaed702",
   "metadata": {},
   "source": [
    "## 2. Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3946b",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1ad28",
   "metadata": {},
   "source": [
    "1. Rename columns for clarity and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c409f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = [\"indicator\", \"grp\", \"state\", \"subgroup\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"value\", \"low_CI\", \"high_CI\", \"confidence_interval\", \"quartile_range\"]\n",
    "df2.columns = [\"id\", \"gender\", \"age\", \"city\", \"profession\", \"academic_pressure\", \"work_pressure\", \"cgpa\", \"study_satisfaction\", \"job_satisfaction\", \"sleep_duration\", \"dietary_habits\", \"degree\", \"has_suicidal_thoughts\", \"work_study_hours\", \"financial_stress\", \"has_family_mental_illness\", \"has_depression\"]\n",
    "df3.columns = [\"gender\", \"age\", \"city\", \"profession\", \"academic_pressure\", \"work_pressure\", \"cgpa\", \"study_satisfaction\", \"job_satisfaction\", \"sleep_duration\", \"dietary_habits\", \"degree\", \"has_suicidal_thoughts\", \"work_study_hours\", \"financial_stress\", \"has_family_mental_illness\", \"has_depression\"]\n",
    "df4.columns = [\"student_id\", \"first_name\", \"last_name\", \"email\", \"gender\", \"age\", \"department\", \"attendance\", \"midterm_score\", \"final_score\", \"assignments_ave\", \"quizzes_ave\", \"participation_score\", \"projects_score\", \"total_score\", \"grade\", \"study_hours_per_week\", \"has_extracurricular\", \"has_internet_access\", \"parent_education_level\", \"family_income_level\", \"stress_level\", \"sleep_hours\"]\n",
    "df5.columns = [\"student_id\", \"age\", \"gender\", \"academic_level\", \"country\", \"ave_daily_usage_hours\", \"most_used_platform\", \"affects_academic_performance\", \"sleep_hours\", \"mental_health_score\", \"relationship_status\", \"conflicts_over_social_media\", \"addicted_score\"] \n",
    "df6.columns = ['age','gender','interest_loss','depressed_mood','sleep_trouble','fatigue','appetite_change','guilt_failure','concentration','fidgety_restless','suicidal_thoughts','phq9_score','depression_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf97498",
   "metadata": {},
   "source": [
    "2. Split DF1 into two dataframes based on gender and age groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "855f4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1[\"grp\"].isin([\"By Age\", \"By Sex\"])]\n",
    "df1_age = df1[df1[\"grp\"] == \"By Age\"].copy()\n",
    "df1_sex = df1[df1[\"grp\"] == \"By Sex\"].copy()\n",
    "df1_age = df1_age.rename(columns={\"subgroup\": \"age\"})\n",
    "df1_sex = df1_sex.rename(columns={\"subgroup\": \"gender\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f7ee9f",
   "metadata": {},
   "source": [
    "3. Drop unnecessary columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e89e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age = df1_age.drop(columns=[\"grp\", \"state\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"quartile_range\"])\n",
    "df1_sex = df1_sex.drop(columns=[\"grp\", \"state\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"quartile_range\"])\n",
    "df2 = df2.drop(columns=[\"id\", \"city\", \"profession\", \"work_pressure\", \"job_satisfaction\"])\n",
    "df3 = df3.drop(columns=[\"city\", \"profession\", \"work_pressure\", \"job_satisfaction\"])\n",
    "df4 = df4.drop(columns=[\"student_id\", \"first_name\", \"last_name\", \"email\", \"grade\"])\n",
    "df5 = df5.drop(columns=[\"student_id\", \"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5e6f6",
   "metadata": {},
   "source": [
    "4. Drop rows with exceeding age groups and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "742a5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age = df1_age[~df1_age[\"age\"].isin(['60 - 69 years', '70 - 79 years', '80 years and above'])]\n",
    "df4 = df4.dropna(subset=[\"attendance\", \"assignments_ave\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264786d",
   "metadata": {},
   "source": [
    "5. Fill missing values with mean and default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fbf47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"financial_stress\"] = df2[\"financial_stress\"].fillna(df2[\"financial_stress\"].mean())\n",
    "df4[\"parent_education_level\"] = df4[\"parent_education_level\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459c874",
   "metadata": {},
   "source": [
    "### Data Type Normalization and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248a3dc",
   "metadata": {},
   "source": [
    "1. Convert age from float to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "047e9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"age\"] = df2[\"age\"].fillna(df2[\"age\"].median()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6986f",
   "metadata": {},
   "source": [
    "2. Convert confidence interval values to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91a96111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age['value'] = pd.to_numeric(df1_age['value'], errors='coerce')\n",
    "df1_age['low_CI'] = pd.to_numeric(df1_age['low_CI'], errors='coerce')\n",
    "df1_age['high_CI'] = pd.to_numeric(df1_age['high_CI'], errors='coerce')\n",
    "\n",
    "df1_sex['value'] = pd.to_numeric(df1_sex['value'], errors='coerce')\n",
    "df1_sex['low_CI'] = pd.to_numeric(df1_sex['low_CI'], errors='coerce')\n",
    "df1_sex['high_CI'] = pd.to_numeric(df1_sex['high_CI'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0304bc",
   "metadata": {},
   "source": [
    "3. Convert boolean columns from 'Yes'/'No' to 1/0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dad8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_columns = {\n",
    "    'df2': [\"has_suicidal_thoughts\", \"has_family_mental_illness\"],\n",
    "    'df3': [\"has_suicidal_thoughts\", \"has_family_mental_illness\", \"has_depression\"],\n",
    "    'df4': [\"has_extracurricular\", \"has_internet_access\"],\n",
    "    'df5': [\"affects_academic_performance\"],\n",
    "}\n",
    "\n",
    "for df_name, columns in bool_columns.items():\n",
    "    df = globals()[df_name]\n",
    "    for col in columns:\n",
    "        df[col] = df[col].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c50a8",
   "metadata": {},
   "source": [
    "4. Map sleep hours to average values in DF2 and DF3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "015a9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_map = {\n",
    "    'Less than 5 hours': 4.5,\n",
    "    '5-6 hours': 5.5,\n",
    "    '7-8 hours': 7.5,\n",
    "    'More than 8 hours': 9,\n",
    "    'Others': None\n",
    "}\n",
    "df2['sleep_duration'] = df2['sleep_duration'].map(sleep_map)\n",
    "df3['sleep_duration'] = df3['sleep_duration'].map(sleep_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871e570",
   "metadata": {},
   "source": [
    "5. Map survery response and depresssion levels to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1d61b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_cols = [\n",
    "    'interest_loss',\n",
    "    'depressed_mood',\n",
    "    'sleep_trouble',\n",
    "    'fatigue',\n",
    "    'appetite_change',\n",
    "    'guilt_failure',\n",
    "    'concentration',\n",
    "    'fidgety_restless',\n",
    "    'suicidal_thoughts'\n",
    "]\n",
    "\n",
    "depression_mapping = {\n",
    "    'Minimal': 0,\n",
    "    'Mild': 1,\n",
    "    'Moderate': 2,\n",
    "    'Moderately Severe': 3,\n",
    "    'Severe': 4\n",
    "}\n",
    "\n",
    "mapping = {\n",
    "    'Not at all': 0,\n",
    "    'Several days': 1,\n",
    "    'More than half the days': 2,\n",
    "    'Nearly every day': 3\n",
    "}\n",
    "\n",
    "df6[survey_cols] = df6[survey_cols].apply(lambda col: col.map(mapping))\n",
    "df6['depression_level'] = df6['depression_level'].map(depression_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39cc5d",
   "metadata": {},
   "source": [
    "6. Apply one-hot encoding to categorical columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "025f68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dietary_habits from DF2 and DF3\n",
    "df2 = pd.concat([df2, pd.get_dummies(df2['dietary_habits'], prefix='diet')], axis=1)\n",
    "df3 = pd.concat([df3, pd.get_dummies(df3['dietary_habits'], prefix='diet')], axis=1)\n",
    "df2.drop(columns=['dietary_habits'], inplace=True)\n",
    "df3.drop(columns=['dietary_habits'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3803b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_used_platform, academic_level, and relationship_status from DF5\n",
    "# Create cleaned dummies and aggregate DF5 to get proportions per (age, gender)\n",
    "df5['most_used_platform'] = df5.get('most_used_platform', '').astype(str).str.strip()\n",
    "df5['relationship_status'] = df5.get('relationship_status', '').astype(str).str.strip()\n",
    "df5['academic_level'] = df5.get('academic_level', '').astype(str).str.strip()\n",
    "\n",
    "# one-hot\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['most_used_platform'], prefix='most_used')], axis=1)\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['relationship_status'], prefix='rel_status')], axis=1)\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['academic_level'], prefix='academic_level')], axis=1)\n",
    "df5.drop(columns=['most_used_platform', 'relationship_status', 'academic_level'], inplace=True, errors='ignore')\n",
    "\n",
    "# numeric columns we care about in DF5\n",
    "df5_num = [c for c in ['ave_daily_usage_hours','affects_academic_performance','sleep_hours','mental_health_score','conflicts_over_social_media','addicted_score'] if c in df5.columns]\n",
    "\n",
    "# collect df5 one-hot columns\n",
    "df5_onehots = [c for c in df5.columns if c.startswith(('most_used_','rel_status_','academic_level_'))]\n",
    "\n",
    "# coerce numeric\n",
    "for c in df5_num:\n",
    "    df5[c] = pd.to_numeric(df5[c], errors='coerce')\n",
    "\n",
    "# Aggregate DF5 by age,gender -> numeric means + one-hot means (fractions)\n",
    "agg_cols = df5_num + df5_onehots\n",
    "if agg_cols:\n",
    "    df5_agg = df5.groupby(['age','gender'], as_index=False)[agg_cols].mean()\n",
    "else:\n",
    "    df5_agg = df5.drop_duplicates(subset=['age','gender'])[['age','gender']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f31af",
   "metadata": {},
   "source": [
    "### Aggregates and Normalization to Fact Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b3160c",
   "metadata": {},
   "source": [
    "Set the minimum and maximum values for the ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f46a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_MIN = 18\n",
    "AGE_MAX = 59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbe236",
   "metadata": {},
   "source": [
    "Helper functions to:\n",
    "- Normalize column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b151c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cols(df):\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_', regex=False)\n",
    "        .str.replace(r'[^0-9a-zA-Z_]', '', regex=True)\n",
    "        .str.replace('__', '_', regex=False)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac2c991",
   "metadata": {},
   "source": [
    "- Make a copy and safely explode df1_age into finer groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca57d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_cdc_age_to_ages(df_age):\n",
    "    import re\n",
    "    df = df_age.copy()\n",
    "    def parse_range(s):\n",
    "        s = str(s)\n",
    "        m = re.search(r\"(\\d+)\\s*-\\s*(\\d+)\", s)\n",
    "        if not m:\n",
    "            return None\n",
    "        lo, hi = int(m.group(1)), int(m.group(2))\n",
    "        return list(range(lo, hi + 1))\n",
    "    df[\"ages\"] = df[\"age\"].map(parse_range)\n",
    "    df = df[df[\"ages\"].notna()].copy()\n",
    "    df = df.explode(\"ages\").rename(columns={\"ages\":\"age\"})\n",
    "    df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df = df[(df[\"age\"] >= AGE_MIN) & (df[\"age\"] <= AGE_MAX)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea102d",
   "metadata": {},
   "source": [
    "1. Normalize column names for all the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ac1a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age = normalize_cols(df1_age)\n",
    "df1_sex = normalize_cols(df1_sex)\n",
    "df2 = normalize_cols(df2)\n",
    "df3 = normalize_cols(df3)\n",
    "df4 = normalize_cols(df4)\n",
    "df5 = normalize_cols(df5)\n",
    "df6 = normalize_cols(df6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d0ca9",
   "metadata": {},
   "source": [
    "2. Ensure age is numeric and within allowed range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e42d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dfn in (\"df2\",\"df3\",\"df4\",\"df5\",\"df6\"):\n",
    "    df = globals()[dfn]\n",
    "    df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\").round().astype(\"Int64\")\n",
    "    df[\"age\"] = df[\"age\"].where((df[\"age\"] >= AGE_MIN) & (df[\"age\"] <= AGE_MAX))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dcff11",
   "metadata": {},
   "source": [
    "3. Clean and convert CDC (df1_age, df1_sex) to numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bcba5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (df1_age, df1_sex):\n",
    "    for col in ['value','low_ci','high_ci']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e57de",
   "metadata": {},
   "source": [
    "- Drop CDC rows outside 18-59 for df1_age and split ranges into two subgroups (18-24,25-29)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dce9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_mapping = {\n",
    "    '18 - 29 years': ['18-24','25-29'],\n",
    "    '30 - 39 years': ['30-34','35-39'],\n",
    "    '40 - 49 years': ['40-44','45-49'],\n",
    "    '50 - 59 years': ['50-54','55-59']\n",
    "}\n",
    "\n",
    "try:\n",
    "    cdc_age_expanded = expand_cdc_age_to_ages(df1_age)\n",
    "except Exception:\n",
    "    cdc_age_expanded = df1_age.copy()\n",
    "    cdc_age_expanded['age_group'] = cdc_age_expanded['age'].map({\n",
    "        '18 - 29 years':'18-24', '30 - 39 years':'30-39', '40 - 49 years':'40-49', '50 - 59 years':'50-59'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aae01d",
   "metadata": {},
   "source": [
    "- Normalize gender names for df1_sex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b4bfbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_sex['gender'] = (df1_sex['gender'].astype(str)\n",
    "                     .str.strip().str.lower().replace({'male':'male','female':'female'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b8d95",
   "metadata": {},
   "source": [
    "- Canonicalize to capitalized or lower consistently; we'll use title case in final dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "302de0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_sex['gender'] = df1_sex['gender'].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223dc95f",
   "metadata": {},
   "source": [
    "4. Prepare one-hot column lists (predictable after normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4249da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_prefixes = ('diet_', 'most_used_', 'rel_status_', 'academic_level_')\n",
    "one_hot_cols = [col for col in pd.concat([df2, df3, df5], ignore_index=True).columns\n",
    "                if col.startswith(onehot_prefixes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd23424f",
   "metadata": {},
   "source": [
    "- Remove duplicates and ensure existence in combined fact_student later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dac44329",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = sorted(set(one_hot_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48081a",
   "metadata": {},
   "source": [
    "5. Build combined student table but avoid creating monstrous intermediate objects.\n",
    "- Merge carefully and then select columns that will be aggregated.\n",
    "- Normalize merge keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33748609",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (df2, df3, df4, df5, df6):\n",
    "    df['gender'] = df['gender'].astype(str).str.strip().str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a131eb",
   "metadata": {},
   "source": [
    "- Start with df2 as base (individual-level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d66d189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b0d4a",
   "metadata": {},
   "source": [
    "- When merging df3, drop columns that are duplicates in base to avoid wide duplication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa18db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_from_df3 = [c for c in ['degree','sleep_duration','diet_healthy','diet_moderate','diet_unhealthy'] if c in df3.columns]\n",
    "df3_for_merge = df3.drop(columns=cols_to_drop_from_df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c74df25",
   "metadata": {},
   "source": [
    "- Merge step-by-step; keep only needed columns to reduce memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ad113ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.merge(df3_for_merge, on=['age','gender'], how='left', suffixes=('','_df3'))\n",
    "\n",
    "# Merge df4: keep numeric/performance columns + department/parent_education_level/family_income_level\n",
    "df4_keep = [c for c in ['attendance','midterm_score','final_score','assignments_ave','quizzes_ave',\n",
    "                        'participation_score','projects_score','total_score','study_hours_per_week',\n",
    "                        'has_extracurricular','has_internet_access','parent_education_level',\n",
    "                        'family_income_level','department','stress_level','sleep_hours'] if c in df4.columns]\n",
    "base = base.merge(df4[df4_keep + ['age','gender']].drop_duplicates(subset=['age','gender']), on=['age','gender'], how='left')\n",
    "\n",
    "# Merge df5 aggregated (proportions) into base\n",
    "df5_keep = [c for c in df5_agg.columns if c not in ['age','gender']]\n",
    "base = base.merge(\n",
    "    df5_agg[['age','gender'] + df5_keep].drop_duplicates(subset=['age','gender']),\n",
    "    on=['age','gender'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge df6: survey and phq9 score\n",
    "df6_keep = [c for c in ['interest_loss','depressed_mood','sleep_trouble','fatigue','appetite_change',\n",
    "                        'guilt_failure','concentration','fidgety_restless','suicidal_thoughts','phq9_score','depression_level','age','gender'] if c in df6.columns]\n",
    "base = base.merge(df6[df6_keep].drop_duplicates(subset=['age','gender']), on=['age','gender'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0dead",
   "metadata": {},
   "source": [
    "6. Identify numeric and one-hot columns for aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7729bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns: numbers and bools (coerce non-numeric to NaN)\n",
    "numeric_candidates = base.select_dtypes(include=['number','bool']).columns.tolist()\n",
    "\n",
    "# Some numeric-like columns may still be object due to NaNs; coerce those we expect to be numeric\n",
    "to_float_try = ['cgpa','academic_pressure','study_satisfaction','work_study_hours','financial_stress',\n",
    "                'attendance','midterm_score','final_score','assignments_ave','quizzes_ave','participation_score',\n",
    "                'projects_score','total_score','study_hours_per_week','stress_level','sleep_hours',\n",
    "                'ave_daily_usage_hours','mental_health_score','conflicts_over_social_media','addicted_score',\n",
    "                'phq9_score']\n",
    "for c in to_float_try:\n",
    "    if c in base.columns:\n",
    "        base[c] = pd.to_numeric(base[c], errors='coerce')\n",
    "\n",
    "# Now recompute numeric columns\n",
    "numeric_cols = [c for c in base.select_dtypes(include=['number','bool','float','int']).columns if c not in ['age']]\n",
    "\n",
    "# Exclude one-hot cols from numeric_cols (we will aggregate them separately)\n",
    "one_hot_cols = [c for c in base.columns if (\n",
    "    c.startswith('diet_') or c.startswith('most_used_') or c.startswith('rel_status_') or c.startswith('academic_level_')\n",
    ")]\n",
    "numeric_non_onehot = [c for c in numeric_cols if c not in one_hot_cols]\n",
    "\n",
    "# Convert numeric_non_onehot to float32 to save memory\n",
    "for c in numeric_non_onehot:\n",
    "    try:\n",
    "        base[c] = base[c].astype('float32')\n",
    "    except Exception:\n",
    "        base[c] = pd.to_numeric(base[c], errors='coerce').astype('float32')\n",
    "\n",
    "# Convert one-hot columns to float32 as well (they are 0/1)\n",
    "for c in one_hot_cols:\n",
    "    base[c] = pd.to_numeric(base[c], errors='coerce').fillna(0).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c47458b",
   "metadata": {},
   "source": [
    "7. Aggregate (memory-safe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "152de70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = [\"age\",\"gender\"]\n",
    "\n",
    "# (A) Numeric non-onehot aggregation\n",
    "numeric_summary = base.groupby(group_cols, as_index=False)[numeric_non_onehot].mean()\n",
    "\n",
    "# (B) One-hot aggregation\n",
    "if one_hot_cols:\n",
    "    onehot_summary = base.groupby(group_cols, as_index=False)[one_hot_cols].mean()\n",
    "    fact_student_summary = pd.merge(numeric_summary, onehot_summary, on=group_cols, how=\"outer\")\n",
    "else:\n",
    "    fact_student_summary = numeric_summary\n",
    "\n",
    "# Rename numeric aggregates\n",
    "rename_map = {c: (\"avg_\" + c) for c in numeric_non_onehot}\n",
    "fact_student_summary.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Keep valid ages only\n",
    "fact_student_summary = fact_student_summary[\n",
    "    fact_student_summary[\"age\"].between(AGE_MIN, AGE_MAX)\n",
    "].sort_values([\"age\",\"gender\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be886d8d",
   "metadata": {},
   "source": [
    "8. Postprocess fact_student_summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f1c7028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact student summary shape: (58, 71)\n",
      "   age  gender  avg_academic_pressure  avg_cgpa  avg_study_satisfaction  \\\n",
      "0   18  Female               3.522059  7.474971                3.307353   \n",
      "1   18    Male               3.506064  7.609261                3.159868   \n",
      "2   19  Female               3.287729  7.588110                3.119887   \n",
      "3   19    Male               3.310223  7.725241                2.968273   \n",
      "4   20  Female               3.372567  7.557442                3.077850   \n",
      "\n",
      "   avg_sleep_duration  avg_has_suicidal_thoughts  avg_work_study_hours  \\\n",
      "0            6.528718                   0.732353              7.447059   \n",
      "1            6.474642                   0.683572              7.223815   \n",
      "2            6.519746                   0.691114              7.224259   \n",
      "3            6.552291                   0.707403              7.316099   \n",
      "4            6.521316                   0.713624              7.060241   \n",
      "\n",
      "   avg_financial_stress  avg_has_family_mental_illness  ...  \\\n",
      "0              3.288235                       0.488235  ...   \n",
      "1              3.264609                       0.468578  ...   \n",
      "2              3.181947                       0.492243  ...   \n",
      "3              3.265570                       0.508813  ...   \n",
      "4              3.396793                       0.518999  ...   \n",
      "\n",
      "   most_used_VKontakte  most_used_WeChat  most_used_WhatsApp  \\\n",
      "0                  0.0          0.000000            0.000000   \n",
      "1                  0.0          0.000000            0.000000   \n",
      "2                  0.0          0.007407            0.059259   \n",
      "3                  0.0          0.035714            0.000000   \n",
      "4                  0.0          0.000000            0.020548   \n",
      "\n",
      "   most_used_YouTube  rel_status_Complicated  rel_status_In Relationship  \\\n",
      "0           0.000000                0.200000                    0.000000   \n",
      "1           0.111111                0.111111                    0.111111   \n",
      "2           0.000000                0.044444                    0.303704   \n",
      "3           0.035714                0.214286                    0.214286   \n",
      "4           0.000000                0.047945                    0.404110   \n",
      "\n",
      "   rel_status_Single  academic_level_Graduate  academic_level_High School  \\\n",
      "0           0.800000                      0.0                    1.000000   \n",
      "1           0.777778                      0.0                    1.000000   \n",
      "2           0.651852                      0.0                    0.059259   \n",
      "3           0.571429                      0.0                    0.107143   \n",
      "4           0.547945                      0.0                    0.013699   \n",
      "\n",
      "   academic_level_Undergraduate  \n",
      "0                      0.000000  \n",
      "1                      0.000000  \n",
      "2                      0.940741  \n",
      "3                      0.892857  \n",
      "4                      0.986301  \n",
      "\n",
      "[5 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "group_cols = [\"age\",\"gender\"]\n",
    "\n",
    "# (A) Numeric non-onehot aggregation\n",
    "numeric_summary = base.groupby(group_cols, as_index=False)[numeric_non_onehot].mean()\n",
    "\n",
    "# (B) One-hot aggregation\n",
    "if one_hot_cols:\n",
    "    onehot_summary = base.groupby(group_cols, as_index=False)[one_hot_cols].mean()\n",
    "    fact_student_summary = pd.merge(numeric_summary, onehot_summary, on=group_cols, how=\"outer\")\n",
    "else:\n",
    "    fact_student_summary = numeric_summary\n",
    "\n",
    "# Rename numeric aggregates\n",
    "rename_map = {c: (\"avg_\" + c) for c in numeric_non_onehot}\n",
    "fact_student_summary.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Keep valid ages only\n",
    "fact_student_summary = fact_student_summary[\n",
    "    fact_student_summary[\"age\"].between(AGE_MIN, AGE_MAX)\n",
    "].sort_values([\"age\",\"gender\"]).reset_index(drop=True)\n",
    "\n",
    "# Rename aggregates to show they are group-level means\n",
    "rename_map = {c: ('avg_' + c) for c in numeric_non_onehot}\n",
    "fact_student_summary.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# one-hot columns represent fractions/proportions\n",
    "fact_student_summary = fact_student_summary.sort_values(['age','gender']).reset_index(drop=True)\n",
    "\n",
    "print(\"Fact student summary shape:\", fact_student_summary.shape)\n",
    "print(fact_student_summary.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96e0cb5",
   "metadata": {},
   "source": [
    "9. Build CDC fact tables (age and sex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d1d146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact CDC age shape: (12, 5)\n",
      "Fact CDC sex shape: (6, 5)\n"
     ]
    }
   ],
   "source": [
    "# df1_age expanded -> cdc_age_expanded already built above\n",
    "# aggregate by indicator, age_group\n",
    "fact_cdc_age = (cdc_age_expanded\n",
    "                .groupby([\"indicator\",\"age\"], as_index=False)\n",
    "                .agg({\"value\":\"mean\",\"low_ci\":\"mean\",\"high_ci\":\"mean\"}))\n",
    "\n",
    "# df1_sex: normalize gender, aggregate by indicator, gender\n",
    "df1_sex[\"gender\"] = df1_sex[\"gender\"].str.title()\n",
    "fact_cdc_sex = (df1_sex\n",
    "                .groupby([\"indicator\",\"gender\"], as_index=False)\n",
    "                .agg({\"value\":\"mean\",\"low_ci\":\"mean\",\"high_ci\":\"mean\"}))\n",
    "\n",
    "print(\"Fact CDC age shape:\", fact_cdc_age.shape)\n",
    "print(\"Fact CDC sex shape:\", fact_cdc_sex.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769aa6bb",
   "metadata": {},
   "source": [
    "10. Build simple dimension tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c842ac44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension tables sizes: age: 42 gender: 2\n"
     ]
    }
   ],
   "source": [
    "dim_age = pd.DataFrame({\"age\": list(range(AGE_MIN, AGE_MAX + 1))})\n",
    "dim_gender = pd.DataFrame({\"gender\": sorted(fact_student_summary[\"gender\"].dropna().unique())})\n",
    "\n",
    "\n",
    "print(\"Dimension tables sizes: age:\", len(dim_age), \"gender:\", len(dim_gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98cd06",
   "metadata": {},
   "source": [
    "11. Show outputs:\n",
    "- fact_student_summary (one row per age_group x gender) is your main fact table for visualizations\n",
    "- fact_cdc_age, fact_cdc_sex are CDC facts for reference\n",
    "- dims: dim_age_group, dim_gender, dim_degree, dim_department, dim_family_income, dim_platform, dim_relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "343b6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_student_summary.to_csv(\"fact_student_summary.csv\", index=False)\n",
    "fact_cdc_age.to_csv(\"fact_cdc_age.csv\", index=False)\n",
    "fact_cdc_sex.to_csv(\"fact_cdc_sex.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b271106",
   "metadata": {},
   "source": [
    "## 3. Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b00ce",
   "metadata": {},
   "source": [
    "Helper for using in-memory DF if available, else load the CSV from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de2dcb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_df(var_name: str, csv_path: str) -> pd.DataFrame:\n",
    "    if var_name in globals() and isinstance(globals()[var_name], pd.DataFrame):\n",
    "        return globals()[var_name]\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0712ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'root'\n",
    "password = 'password'\n",
    "host = 'localhost'          \n",
    "port = '3306'               \n",
    "database = 'olap_dashboard'  \n",
    "\n",
    "engine = create_engine(\"mysql+mysqlconnector://root:password@localhost:3306/olap_dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0513efd",
   "metadata": {},
   "source": [
    "1) Read connection settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f16accbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "MYSQL_HOST = os.getenv(\"MYSQL_HOST\", \"localhost\")\n",
    "MYSQL_PORT = int(os.getenv(\"MYSQL_PORT\", \"3306\"))\n",
    "MYSQL_DB   = os.getenv(\"MYSQL_DB\", \"olap_dashboard\")\n",
    "MYSQL_USER = os.getenv(\"MYSQL_USER\", \"root\")\n",
    "MYSQL_PWD  = os.getenv(\"MYSQL_PASSWORD\", \"admin\")\n",
    "\n",
    "if not MYSQL_PWD:\n",
    "    raise RuntimeError(\"Missing MYSQL_PASSWORD. Put it in .env or export it in your terminal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea7c23",
   "metadata": {},
   "source": [
    "2) Ensure database exists (connect to server without DB first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4d9517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "server_url = f\"mysql+pymysql://{MYSQL_USER}:{MYSQL_PWD}@{MYSQL_HOST}:{MYSQL_PORT}\"\n",
    "server_engine = create_engine(server_url, pool_pre_ping=True)\n",
    "\n",
    "with server_engine.connect() as conn:\n",
    "    conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS `{MYSQL_DB}` CHARACTER SET utf8mb4\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0ec96",
   "metadata": {},
   "source": [
    "3) Connect to the specific DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "576d31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = f\"{server_url}/{MYSQL_DB}?charset=utf8mb4\"\n",
    "engine = create_engine(db_url, pool_pre_ping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f5af8",
   "metadata": {},
   "source": [
    "4) Get data to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5bd0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_student_summary_df = ensure_df(\"fact_student_summary\", \"fact_student_summary.csv\")\n",
    "fact_cdc_age_df         = ensure_df(\"fact_cdc_age\", \"fact_cdc_age.csv\")\n",
    "fact_cdc_sex_df         = ensure_df(\"fact_cdc_sex\", \"fact_cdc_sex.csv\")\n",
    "\n",
    "# Enforce key dtypes to match schema (age INT, gender VARCHAR, indicator VARCHAR)\n",
    "fact_student_summary_df[\"age\"] = pd.to_numeric(fact_student_summary_df[\"age\"], errors=\"coerce\").astype(\"Int64\")\n",
    "fact_student_summary_df[\"gender\"] = fact_student_summary_df[\"gender\"].astype(str).str.title()\n",
    "fact_student_summary_df = fact_student_summary_df.dropna(subset=[\"age\",\"gender\"])\n",
    "\n",
    "fact_cdc_age_df[\"age\"] = pd.to_numeric(fact_cdc_age_df[\"age\"], errors=\"coerce\").astype(\"Int64\")\n",
    "fact_cdc_age_df = fact_cdc_age_df.dropna(subset=[\"indicator\",\"age\"])\n",
    "fact_cdc_age_df[\"indicator\"] = fact_cdc_age_df[\"indicator\"].astype(str)\n",
    "\n",
    "fact_cdc_sex_df[\"gender\"] = fact_cdc_sex_df[\"gender\"].astype(str).str.title()\n",
    "fact_cdc_sex_df[\"indicator\"] = fact_cdc_sex_df[\"indicator\"].astype(str)\n",
    "fact_cdc_sex_df = fact_cdc_sex_df.dropna(subset=[\"indicator\",\"gender\"])\n",
    "\n",
    "# Set MySQL dtypes for key columns\n",
    "from sqlalchemy.types import Integer, String\n",
    "\n",
    "fss_dtypes = {\"age\": Integer(), \"gender\": String(16)}\n",
    "cdc_age_dtypes = {\"indicator\": String(128), \"age\": Integer()}\n",
    "cdc_sex_dtypes = {\"indicator\": String(128), \"gender\": String(16)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d40280",
   "metadata": {},
   "source": [
    "5) Write to MySQL (overwrite for repeatable runs; change to 'append' if preferred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a6c7801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading tables to MySQL...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Uploading tables to MySQL...\")\n",
    "fact_student_summary_df.to_sql(\n",
    "    \"fact_student_summary\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\", dtype=fss_dtypes\n",
    ")\n",
    "fact_cdc_age_df.to_sql(\n",
    "    \"fact_cdc_age\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\", dtype=cdc_age_dtypes\n",
    ")\n",
    "fact_cdc_sex_df.to_sql(\n",
    "    \"fact_cdc_sex\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\", dtype=cdc_sex_dtypes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d291d60",
   "metadata": {},
   "source": [
    "6) Quick verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b14d1870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fact_student_summary: 58 rows\n",
      "fact_cdc_age: 0 rows\n",
      "fact_cdc_sex: 6 rows\n",
      "Load complete.\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn:\n",
    "    for tbl in (\"fact_student_summary\", \"fact_cdc_age\", \"fact_cdc_sex\"):\n",
    "        n = conn.execute(text(f\"SELECT COUNT(*) FROM `{tbl}`\")).scalar()\n",
    "        print(f\"{tbl}: {n} rows\")\n",
    "\n",
    "print(\"Load complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1fe21f",
   "metadata": {},
   "source": [
    "### Dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ce1f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_age: 42 rows\n",
      "dim_gender: 2 rows\n",
      "Dimension load complete.\n"
     ]
    }
   ],
   "source": [
    "required_dims = [\n",
    "    \"dim_age\",\"dim_gender\",\n",
    "]\n",
    "missing = [d for d in required_dims if d not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing dimension dataframes: {missing}. Run Transform first.\")\n",
    "\n",
    "# Deduplicate\n",
    "dim_age    = dim_age.drop_duplicates(subset=[\"age\"]).sort_values(\"age\")\n",
    "dim_gender = dim_gender.drop_duplicates(subset=[\"gender\"]).sort_values(\"gender\")\n",
    "\n",
    "# Write\n",
    "dim_age.to_sql(\"dim_age\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "dim_gender.to_sql(\"dim_gender\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "\n",
    "# Verify\n",
    "with engine.connect() as conn:\n",
    "    for tbl in (\"dim_age\",\"dim_gender\"):\n",
    "        n = conn.execute(text(f\"SELECT COUNT(*) FROM `{tbl}`\")).scalar()\n",
    "        print(f\"{tbl}: {n} rows\")\n",
    "\n",
    "print(\"Dimension load complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6ba953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys and constraints applied.\n"
     ]
    }
   ],
   "source": [
    "# Add primary/foreign keys after loads\n",
    "def run(sql):\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(text(sql))\n",
    "    except Exception as e:\n",
    "        print(\"Skip:\", e)\n",
    "\n",
    "# Dimension PKs\n",
    "run(\"ALTER TABLE dim_age MODIFY age INT NOT NULL;\")\n",
    "run(\"ALTER TABLE dim_age ADD PRIMARY KEY (age);\")\n",
    "\n",
    "run(\"ALTER TABLE dim_gender MODIFY gender VARCHAR(16) NOT NULL;\")\n",
    "run(\"ALTER TABLE dim_gender ADD PRIMARY KEY (gender);\")\n",
    "\n",
    "# Fact keys/FKs\n",
    "run(\"ALTER TABLE fact_student_summary MODIFY age INT NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_student_summary MODIFY gender VARCHAR(16) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_student_summary ADD PRIMARY KEY (age, gender);\")\n",
    "run(\"\"\"\n",
    "ALTER TABLE fact_student_summary\n",
    "  ADD CONSTRAINT fk_fss_age FOREIGN KEY (age) REFERENCES dim_age(age)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT,\n",
    "  ADD CONSTRAINT fk_fss_gender FOREIGN KEY (gender) REFERENCES dim_gender(gender)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT;\n",
    "\"\"\")\n",
    "\n",
    "run(\"ALTER TABLE fact_cdc_age MODIFY indicator VARCHAR(128) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_age MODIFY age INT NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_age ADD PRIMARY KEY (indicator, age);\")\n",
    "run(\"\"\"\n",
    "ALTER TABLE fact_cdc_age\n",
    "  ADD CONSTRAINT fk_cdc_age_age FOREIGN KEY (age) REFERENCES dim_age(age)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT;\n",
    "\"\"\")\n",
    "\n",
    "# fact_cdc_sex(indicator, gender)\n",
    "run(\"ALTER TABLE fact_cdc_sex MODIFY indicator VARCHAR(128) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_sex MODIFY gender VARCHAR(16) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_sex ADD PRIMARY KEY (indicator, gender);\")\n",
    "run(\"\"\"\n",
    "ALTER TABLE fact_cdc_sex\n",
    "  ADD CONSTRAINT fk_cdc_sex_gender FOREIGN KEY (gender) REFERENCES dim_gender(gender)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT;\n",
    "\"\"\")\n",
    "\n",
    "print(\"Keys and constraints applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d44c2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = {\n",
    "    \"dim_age\": dim_age,\n",
    "    \"dim_gender\": dim_gender,\n",
    "}\n",
    "for name, df in dims.items():\n",
    "    df.to_csv(f\"{name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
