{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b08927",
   "metadata": {},
   "source": [
    "# ETL Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5dff2",
   "metadata": {},
   "source": [
    "## 1. Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a45fc",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29bb4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4124f",
   "metadata": {},
   "source": [
    "Read datasets\n",
    "1. Indicators of Anxiety or Depression Based on Reported Frequency of Symptoms During Last 7 Days\n",
    "2. Student Depression Dataset\n",
    "3. Student Mental Health Crisis After COVID-19\n",
    "4. Student Performance and Behavior Dataset\n",
    "5. Students Social Media Addiction Dataset\n",
    "6. PHQ-9 Student Depression Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6804be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json(\"datasets/cdc-indicators-of-anxiety-or-depression.json\")\n",
    "df2 = pd.read_csv(\"datasets/kaggle-student-depression-dataset.csv\")\n",
    "df3 = pd.read_excel(\"datasets/kaggle-student-mental-health-crisis-after-covid19-final.xlsx\")\n",
    "df4 = pd.read_json(\"datasets/kaggle-student-performance-and-behavior-dataset.json\")\n",
    "df5 = pd.read_csv(\"datasets/kaggle-students-social-media-addiction.csv\")\n",
    "df6 = pd.read_csv(\"datasets/mendeley-phq9-student-depression-dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaed702",
   "metadata": {},
   "source": [
    "## 2. Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3946b",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1ad28",
   "metadata": {},
   "source": [
    "1. Rename columns for clarity and consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c409f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = [\"indicator\", \"grp\", \"state\", \"subgroup\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"value\", \"low_CI\", \"high_CI\", \"confidence_interval\", \"quartile_range\"]\n",
    "df2.columns = [\"id\", \"gender\", \"age\", \"city\", \"profession\", \"academic_pressure\", \"work_pressure\", \"cgpa\", \"study_satisfaction\", \"job_satisfaction\", \"sleep_duration\", \"dietary_habits\", \"degree\", \"has_suicidal_thoughts\", \"work_study_hours\", \"financial_stress\", \"has_family_mental_illness\", \"has_depression\"]\n",
    "df3.columns = [\"gender\", \"age\", \"city\", \"profession\", \"academic_pressure\", \"work_pressure\", \"cgpa\", \"study_satisfaction\", \"job_satisfaction\", \"sleep_duration\", \"dietary_habits\", \"degree\", \"has_suicidal_thoughts\", \"work_study_hours\", \"financial_stress\", \"has_family_mental_illness\", \"has_depression\"]\n",
    "df4.columns = [\"student_id\", \"first_name\", \"last_name\", \"email\", \"gender\", \"age\", \"department\", \"attendance\", \"midterm_score\", \"final_score\", \"assignments_ave\", \"quizzes_ave\", \"participation_score\", \"projects_score\", \"total_score\", \"grade\", \"study_hours_per_week\", \"has_extracurricular\", \"has_internet_access\", \"parent_education_level\", \"family_income_level\", \"stress_level\", \"sleep_hours\"]\n",
    "df5.columns = [\"student_id\", \"age\", \"gender\", \"academic_level\", \"country\", \"ave_daily_usage_hours\", \"most_used_platform\", \"affects_academic_performance\", \"sleep_hours\", \"mental_health_score\", \"relationship_status\", \"conflicts_over_social_media\", \"addicted_score\"] \n",
    "df6.columns = ['age','gender','interest_loss','depressed_mood','sleep_trouble','fatigue','appetite_change','guilt_failure','concentration','fidgety_restless','suicidal_thoughts','phq9_score','depression_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf97498",
   "metadata": {},
   "source": [
    "2. Split DF1 into two dataframes based on gender and age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "855f4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1[\"grp\"].isin([\"By Age\", \"By Sex\"])]\n",
    "df1_age = df1[df1[\"grp\"] == \"By Age\"].copy()\n",
    "df1_sex = df1[df1[\"grp\"] == \"By Sex\"].copy()\n",
    "df1_age = df1_age.rename(columns={\"subgroup\": \"age\"})\n",
    "df1_sex = df1_sex.rename(columns={\"subgroup\": \"gender\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f7ee9f",
   "metadata": {},
   "source": [
    "3. Drop unnecessary columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e89e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age = df1_age.drop(columns=[\"grp\", \"state\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"quartile_range\"])\n",
    "df1_sex = df1_sex.drop(columns=[\"grp\", \"state\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"quartile_range\"])\n",
    "df2 = df2.drop(columns=[\"id\", \"city\", \"profession\", \"work_pressure\", \"job_satisfaction\"])\n",
    "df3 = df3.drop(columns=[\"city\", \"profession\", \"work_pressure\", \"job_satisfaction\"])\n",
    "df4 = df4.drop(columns=[\"student_id\", \"first_name\", \"last_name\", \"email\", \"grade\"])\n",
    "df5 = df5.drop(columns=[\"student_id\", \"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5e6f6",
   "metadata": {},
   "source": [
    "4. Drop rows with exceeding age groups and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742a5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age = df1_age[~df1_age[\"age\"].isin(['60 - 69 years', '70 - 79 years', '80 years and above'])]\n",
    "df4 = df4.dropna(subset=[\"attendance\", \"assignments_ave\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264786d",
   "metadata": {},
   "source": [
    "5. Fill missing values with mean and default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fbf47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"financial_stress\"] = df2[\"financial_stress\"].fillna(df2[\"financial_stress\"].mean())\n",
    "df4[\"parent_education_level\"] = df4[\"parent_education_level\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459c874",
   "metadata": {},
   "source": [
    "### Data Type Normalization and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248a3dc",
   "metadata": {},
   "source": [
    "1. Convert age from float to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "047e9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"age\"] = df2[\"age\"].fillna(df2[\"age\"].median()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6986f",
   "metadata": {},
   "source": [
    "2. Convert confidence interval values to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a96111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age['value'] = pd.to_numeric(df1_age['value'], errors='coerce')\n",
    "df1_age['low_CI'] = pd.to_numeric(df1_age['low_CI'], errors='coerce')\n",
    "df1_age['high_CI'] = pd.to_numeric(df1_age['high_CI'], errors='coerce')\n",
    "\n",
    "df1_sex['value'] = pd.to_numeric(df1_sex['value'], errors='coerce')\n",
    "df1_sex['low_CI'] = pd.to_numeric(df1_sex['low_CI'], errors='coerce')\n",
    "df1_sex['high_CI'] = pd.to_numeric(df1_sex['high_CI'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0304bc",
   "metadata": {},
   "source": [
    "3. Convert boolean columns from 'Yes'/'No' to 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dad8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_columns = {\n",
    "    'df2': [\"has_suicidal_thoughts\", \"has_family_mental_illness\"],\n",
    "    'df3': [\"has_suicidal_thoughts\", \"has_family_mental_illness\", \"has_depression\"],\n",
    "    'df4': [\"has_extracurricular\", \"has_internet_access\"],\n",
    "    'df5': [\"affects_academic_performance\"],\n",
    "}\n",
    "\n",
    "for df_name, columns in bool_columns.items():\n",
    "    df = globals()[df_name]\n",
    "    for col in columns:\n",
    "        df[col] = df[col].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c50a8",
   "metadata": {},
   "source": [
    "4. Map sleep hours to average values in DF2 and DF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015a9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_map = {\n",
    "    'Less than 5 hours': 4.5,\n",
    "    '5-6 hours': 5.5,\n",
    "    '7-8 hours': 7.5,\n",
    "    'More than 8 hours': 9,\n",
    "    'Others': None\n",
    "}\n",
    "df2['sleep_duration'] = df2['sleep_duration'].map(sleep_map)\n",
    "df3['sleep_duration'] = df3['sleep_duration'].map(sleep_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871e570",
   "metadata": {},
   "source": [
    "5. Map survery response and depresssion levels to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1d61b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_cols = [\n",
    "    'interest_loss',\n",
    "    'depressed_mood',\n",
    "    'sleep_trouble',\n",
    "    'fatigue',\n",
    "    'appetite_change',\n",
    "    'guilt_failure',\n",
    "    'concentration',\n",
    "    'fidgety_restless',\n",
    "    'suicidal_thoughts'\n",
    "]\n",
    "\n",
    "depression_mapping = {\n",
    "    'Minimal': 0,\n",
    "    'Mild': 1,\n",
    "    'Moderate': 2,\n",
    "    'Moderately Severe': 3,\n",
    "    'Severe': 4\n",
    "}\n",
    "\n",
    "mapping = {\n",
    "    'Not at all': 0,\n",
    "    'Several days': 1,\n",
    "    'More than half the days': 2,\n",
    "    'Nearly every day': 3\n",
    "}\n",
    "\n",
    "df6[survey_cols] = df6[survey_cols].apply(lambda col: col.map(mapping))\n",
    "df6['depression_level'] = df6['depression_level'].map(depression_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "963a1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode academic_level in DF5\n",
    "df5['academic_level'] = df5['academic_level'].astype(str).str.strip()\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['academic_level'], prefix='academic_level')], axis=1)\n",
    "df5.drop(columns=['academic_level'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "025f68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode dietary_habits in DF2 and DF3\n",
    "df2 = pd.concat([df2, pd.get_dummies(df2['dietary_habits'], prefix='diet')], axis=1)\n",
    "df3 = pd.concat([df3, pd.get_dummies(df3['dietary_habits'], prefix='diet')], axis=1)\n",
    "df2.drop(columns=['dietary_habits'], inplace=True)\n",
    "df3.drop(columns=['dietary_habits'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3803b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode most_used_platform and relationship_status in DF5\n",
    "df5['relationship_status'] = df5['relationship_status'].str.strip().str.lower().str.replace(' ', '_')\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['most_used_platform'], prefix='most_used')], axis=1)\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['relationship_status'], prefix='rel_status')], axis=1)\n",
    "df5.drop(columns=['most_used_platform', 'relationship_status'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea4b0a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'age', 'academic_pressure', 'cgpa', 'study_satisfaction', 'sleep_duration', 'degree', 'has_suicidal_thoughts', 'work_study_hours', 'financial_stress', 'has_family_mental_illness', 'has_depression', 'diet_Healthy', 'diet_Moderate', 'diet_Unhealthy']\n"
     ]
    }
   ],
   "source": [
    "print(df3.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f31af",
   "metadata": {},
   "source": [
    "### Aggregate to Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "343b6b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact student summary shape: (58, 71)\n",
      "   age  gender  avg_academic_pressure  avg_cgpa  avg_study_satisfaction  \\\n",
      "0   18  Female               3.522059  7.474971                3.307353   \n",
      "1   18    Male               3.506064  7.609262                3.159868   \n",
      "2   19  Female               3.287729  7.588110                3.119887   \n",
      "3   19    Male               3.310223  7.725241                2.968273   \n",
      "4   20  Female               3.372567  7.557442                3.077850   \n",
      "\n",
      "   avg_sleep_duration  avg_has_suicidal_thoughts  avg_work_study_hours  \\\n",
      "0            6.528718                   0.732353              7.447059   \n",
      "1            6.474642                   0.683572              7.223815   \n",
      "2            6.519746                   0.691114              7.224259   \n",
      "3            6.552291                   0.707403              7.316099   \n",
      "4            6.521316                   0.713624              7.060241   \n",
      "\n",
      "   avg_financial_stress  avg_has_family_mental_illness  ...  \\\n",
      "0              3.288235                       0.488235  ...   \n",
      "1              3.264609                       0.468578  ...   \n",
      "2              3.181947                       0.492243  ...   \n",
      "3              3.265570                       0.508813  ...   \n",
      "4              3.396793                       0.518999  ...   \n",
      "\n",
      "   most_used_snapchat  most_used_tiktok  most_used_twitter  \\\n",
      "0                 0.0               0.0                0.0   \n",
      "1                 0.0               0.0                0.0   \n",
      "2                 0.0               0.0                0.0   \n",
      "3                 1.0               0.0                0.0   \n",
      "4                 0.0               1.0                0.0   \n",
      "\n",
      "   most_used_vkontakte  most_used_wechat  most_used_whatsapp  \\\n",
      "0                  0.0               0.0                 0.0   \n",
      "1                  0.0               0.0                 0.0   \n",
      "2                  0.0               0.0                 0.0   \n",
      "3                  0.0               0.0                 0.0   \n",
      "4                  0.0               0.0                 0.0   \n",
      "\n",
      "   most_used_youtube  rel_status_complicated  rel_status_in_relationship  \\\n",
      "0                0.0                     0.0                         0.0   \n",
      "1                1.0                     0.0                         0.0   \n",
      "2                0.0                     0.0                         1.0   \n",
      "3                0.0                     1.0                         0.0   \n",
      "4                0.0                     1.0                         0.0   \n",
      "\n",
      "   rel_status_single  \n",
      "0                1.0  \n",
      "1                1.0  \n",
      "2                0.0  \n",
      "3                0.0  \n",
      "4                0.0  \n",
      "\n",
      "[5 rows x 71 columns]\n",
      "Fact CDC age shape: (12, 5)\n",
      "Fact CDC sex shape: (6, 5)\n",
      "Dimension tables sizes: age: 42 gender: 2 platforms: 12\n"
     ]
    }
   ],
   "source": [
    "# ---------- 0. SETTINGS ----------\n",
    "AGE_MIN = 18\n",
    "AGE_MAX = 59\n",
    "\n",
    "# helper to normalize column names\n",
    "def normalize_cols(df):\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_', regex=False)\n",
    "        .str.replace(r'[^0-9a-zA-Z_]', '', regex=True)  # remove weird chars\n",
    "        .str.replace('__', '_', regex=False)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# ---------- 1. Normalize column names for all dataframes ----------\n",
    "df1_age = normalize_cols(df1_age)\n",
    "df1_sex = normalize_cols(df1_sex)\n",
    "df2 = normalize_cols(df2)\n",
    "df3 = normalize_cols(df3)\n",
    "df4 = normalize_cols(df4)\n",
    "df5 = normalize_cols(df5)\n",
    "df6 = normalize_cols(df6)\n",
    "\n",
    "# ---------- 2. Ensure age is numeric and within allowed range (df2..df6) ----------\n",
    "for dfn in (\"df2\",\"df3\",\"df4\",\"df5\",\"df6\"):\n",
    "    df = globals()[dfn]\n",
    "    df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\").round().astype(\"Int64\")\n",
    "    df[\"age\"] = df[\"age\"].where((df[\"age\"] >= AGE_MIN) & (df[\"age\"] <= AGE_MAX))\n",
    "\n",
    "# ---------- 3. Clean and convert CDC (df1_age, df1_sex) numeric columns ----------\n",
    "for df in (df1_age, df1_sex):\n",
    "    for col in ['value','low_ci','high_ci']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# OPTIONAL: drop CDC rows outside 18-59 for df1_age (based on textual ranges)\n",
    "# We will split ranges like '18 - 29 years' into two subgroups (18-24,25-29)\n",
    "split_mapping = {\n",
    "    '18 - 29 years': ['18-24','25-29'],\n",
    "    '30 - 39 years': ['30-34','35-39'],\n",
    "    '40 - 49 years': ['40-44','45-49'],\n",
    "    '50 - 59 years': ['50-54','55-59']\n",
    "}\n",
    "\n",
    "# Make a copy and safely explode df1_age into finer groups\n",
    "def expand_cdc_age_to_ages(df_age):\n",
    "    import re\n",
    "    df = df_age.copy()\n",
    "    # normalize column names first (already done earlier in your notebook)\n",
    "    # parse like \"18 - 29 years\" -> range(18, 30)\n",
    "    def parse_range(s):\n",
    "        s = str(s)\n",
    "        m = re.search(r\"(\\d+)\\s*-\\s*(\\d+)\", s)\n",
    "        if not m:\n",
    "            return None\n",
    "        lo, hi = int(m.group(1)), int(m.group(2))\n",
    "        return list(range(lo, hi + 1))\n",
    "    df[\"ages\"] = df[\"age\"].map(parse_range)\n",
    "    df = df[df[\"ages\"].notna()].copy()\n",
    "    df = df.explode(\"ages\").rename(columns={\"ages\":\"age\"})\n",
    "    df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    # keep only desired age window\n",
    "    df = df[(df[\"age\"] >= AGE_MIN) & (df[\"age\"] <= AGE_MAX)]\n",
    "    return df\n",
    "\n",
    "# Apply expansion (if df1_age uses textual ranges as you showed)\n",
    "try:\n",
    "    cdc_age_expanded = expand_cdc_age_to_ages(df1_age)\n",
    "except Exception:\n",
    "    # if mapping fails for any reason, fall back to filtering and mapping directly if exact matches exist\n",
    "    cdc_age_expanded = df1_age.copy()\n",
    "    cdc_age_expanded['age_group'] = cdc_age_expanded['age'].map({\n",
    "        '18 - 29 years':'18-24', '30 - 39 years':'30-39', '40 - 49 years':'40-49', '50 - 59 years':'50-59'\n",
    "    })\n",
    "\n",
    "# For df1_sex ensure gender names are normalized\n",
    "df1_sex['gender'] = (df1_sex['gender'].astype(str)\n",
    "                     .str.strip().str.lower().replace({'male':'male','female':'female'}))\n",
    "# canonicalize to capitalized or lower consistently; we'll use title case in final dims\n",
    "df1_sex['gender'] = df1_sex['gender'].str.title()\n",
    "\n",
    "# ---------- 4. Prepare one-hot column lists (after normalization these are predictable) ----------\n",
    "onehot_prefixes = ('diet_', 'most_used_', 'rel_status_', 'academic_level_')\n",
    "one_hot_cols = [col for col in pd.concat([df2, df3, df5], ignore_index=True).columns\n",
    "                if col.startswith(onehot_prefixes)]\n",
    "\n",
    "# Remove duplicates and ensure existence in combined fact_student later\n",
    "one_hot_cols = sorted(set(one_hot_cols))\n",
    "\n",
    "# ---------- 5. Build combined student table but avoid creating monstrous intermediate objects ----------\n",
    "# We'll not concat all rows wide first; instead we'll merge carefully and then select columns we will aggregate.\n",
    "\n",
    "# Normalize merge keys\n",
    "for df in (df2, df3, df4, df5, df6):\n",
    "    df['gender'] = df['gender'].astype(str).str.strip().str.title()\n",
    "\n",
    "# Start with df2 as base (individual-level)\n",
    "base = df2.copy()\n",
    "\n",
    "# When merging df3, drop columns that are duplicates in base to avoid wide duplication\n",
    "cols_to_drop_from_df3 = [c for c in ['degree','sleep_duration','diet_healthy','diet_moderate','diet_unhealthy'] if c in df3.columns]\n",
    "df3_for_merge = df3.drop(columns=cols_to_drop_from_df3)\n",
    "\n",
    "# Merge step-by-step; keep only needed columns to reduce memory\n",
    "base = base.merge(df3_for_merge, on=['age','gender'], how='left', suffixes=('','_df3'))\n",
    "\n",
    "# Merge df4: keep numeric/performance columns + department/parent_education_level/family_income_level\n",
    "df4_keep = [c for c in ['attendance','midterm_score','final_score','assignments_ave','quizzes_ave',\n",
    "                        'participation_score','projects_score','total_score','study_hours_per_week',\n",
    "                        'has_extracurricular','has_internet_access','parent_education_level',\n",
    "                        'family_income_level','department','stress_level','sleep_hours'] if c in df4.columns]\n",
    "base = base.merge(df4[df4_keep + ['age','gender']].drop_duplicates(subset=['age','gender']), on=['age','gender'], how='left')\n",
    "\n",
    "# Merge df5: keep numeric + one-hot platform + rel_status + academic_level\n",
    "df5_keep = [c for c in df5.columns if c in ['ave_daily_usage_hours','affects_academic_performance',\n",
    "                                            'sleep_hours','mental_health_score','conflicts_over_social_media','addicted_score',\n",
    "                                            'age','gender']]\n",
    "# also include any one-hot platform, relationship, and academic_level columns\n",
    "df5_onehots = [c for c in df5.columns if c.startswith('most_used_') or c.startswith('rel_status_') or c.startswith('academic_level_')]\n",
    "df5_keep = list(dict.fromkeys(df5_keep + df5_onehots))  # preserve order\n",
    "base = base.merge(\n",
    "    df5[df5_keep].drop_duplicates(subset=['age','gender']),\n",
    "    on=['age','gender'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge df6: survey and phq9 score\n",
    "df6_keep = [c for c in ['interest_loss','depressed_mood','sleep_trouble','fatigue','appetite_change',\n",
    "                        'guilt_failure','concentration','fidgety_restless','suicidal_thoughts','phq9_score','depression_level','age','gender'] if c in df6.columns]\n",
    "base = base.merge(df6[df6_keep].drop_duplicates(subset=['age','gender']), on=['age','gender'], how='left')\n",
    "\n",
    "# Now 'base' is a reasonably-wide per-student table but not exploded by duplicated columns.\n",
    "\n",
    "# ---------- 6. Identify numeric and one-hot columns for aggregation ----------\n",
    "# Numeric columns: numbers and bools (coerce non-numeric to NaN)\n",
    "numeric_candidates = base.select_dtypes(include=['number','bool']).columns.tolist()\n",
    "\n",
    "# Some numeric-like columns may still be object due to NaNs; coerce those we expect to be numeric\n",
    "to_float_try = ['cgpa','academic_pressure','study_satisfaction','work_study_hours','financial_stress',\n",
    "                'attendance','midterm_score','final_score','assignments_ave','quizzes_ave','participation_score',\n",
    "                'projects_score','total_score','study_hours_per_week','stress_level','sleep_hours',\n",
    "                'ave_daily_usage_hours','mental_health_score','conflicts_over_social_media','addicted_score',\n",
    "                'phq9_score']\n",
    "for c in to_float_try:\n",
    "    if c in base.columns:\n",
    "        base[c] = pd.to_numeric(base[c], errors='coerce')\n",
    "\n",
    "# Now recompute numeric columns\n",
    "numeric_cols = [c for c in base.select_dtypes(include=['number','bool','float','int']).columns if c not in ['age']]\n",
    "\n",
    "# Exclude one-hot cols from numeric_cols (we will aggregate them separately)\n",
    "one_hot_cols = [c for c in base.columns if (\n",
    "    c.startswith('diet_') or c.startswith('most_used_') or c.startswith('rel_status_') or c.startswith('academic_level_')\n",
    ")]\n",
    "numeric_non_onehot = [c for c in numeric_cols if c not in one_hot_cols]\n",
    "\n",
    "# Convert numeric_non_onehot to float32 to save memory\n",
    "for c in numeric_non_onehot:\n",
    "    try:\n",
    "        base[c] = base[c].astype('float32')\n",
    "    except Exception:\n",
    "        base[c] = pd.to_numeric(base[c], errors='coerce').astype('float32')\n",
    "\n",
    "# Convert one-hot columns to float32 as well (they are 0/1)\n",
    "for c in one_hot_cols:\n",
    "    base[c] = pd.to_numeric(base[c], errors='coerce').fillna(0).astype('float32')\n",
    "\n",
    "# ---------- 7. Aggregate (memory-safe) ----------\n",
    "group_cols = [\"age\",\"gender\"]\n",
    "\n",
    "# (A) Numeric non-onehot aggregation\n",
    "numeric_summary = base.groupby(group_cols, as_index=False)[numeric_non_onehot].mean()\n",
    "\n",
    "# (B) One-hot aggregation\n",
    "if one_hot_cols:\n",
    "    onehot_summary = base.groupby(group_cols, as_index=False)[one_hot_cols].mean()\n",
    "    fact_student_summary = pd.merge(numeric_summary, onehot_summary, on=group_cols, how=\"outer\")\n",
    "else:\n",
    "    fact_student_summary = numeric_summary\n",
    "\n",
    "# Rename numeric aggregates\n",
    "rename_map = {c: (\"avg_\" + c) for c in numeric_non_onehot}\n",
    "fact_student_summary.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Keep valid ages only\n",
    "fact_student_summary = fact_student_summary[\n",
    "    fact_student_summary[\"age\"].between(AGE_MIN, AGE_MAX)\n",
    "].sort_values([\"age\",\"gender\"]).reset_index(drop=True)\n",
    "\n",
    "# ---------- 8. Postprocess fact_student_summary ----------\n",
    "# Optionally rename aggregates to make it clear they are group-level means\n",
    "# e.g., add prefix 'avg_' to numeric_non_onehot columns\n",
    "rename_map = {c: ('avg_' + c) for c in numeric_non_onehot}\n",
    "fact_student_summary.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# one-hot columns already represent fractions/proportions (0..1)\n",
    "# reset index order\n",
    "fact_student_summary = fact_student_summary.sort_values(['age','gender']).reset_index(drop=True)\n",
    "\n",
    "print(\"Fact student summary shape:\", fact_student_summary.shape)\n",
    "print(fact_student_summary.head())\n",
    "\n",
    "# ---------- 9. Build CDC fact tables (age and sex) ----------\n",
    "# df1_age expanded -> cdc_age_expanded already built above\n",
    "# aggregate by indicator, age_group\n",
    "fact_cdc_age = (cdc_age_expanded\n",
    "                .groupby([\"indicator\",\"age\"], as_index=False)\n",
    "                .agg({\"value\":\"mean\",\"low_ci\":\"mean\",\"high_ci\":\"mean\"}))\n",
    "\n",
    "# df1_sex: normalize gender, aggregate by indicator, gender\n",
    "df1_sex[\"gender\"] = df1_sex[\"gender\"].str.title()\n",
    "fact_cdc_sex = (df1_sex\n",
    "                .groupby([\"indicator\",\"gender\"], as_index=False)\n",
    "                .agg({\"value\":\"mean\",\"low_ci\":\"mean\",\"high_ci\":\"mean\"}))\n",
    "\n",
    "print(\"Fact CDC age shape:\", fact_cdc_age.shape)\n",
    "print(\"Fact CDC sex shape:\", fact_cdc_sex.shape)\n",
    "\n",
    "# ---------- 10. Build simple dimension tables ----------\n",
    "dim_age = pd.DataFrame({\"age\": list(range(AGE_MIN, AGE_MAX + 1))})\n",
    "dim_gender = pd.DataFrame({\"gender\": sorted(fact_student_summary[\"gender\"].dropna().unique())})\n",
    "\n",
    "# platforms only (others removed as they are not connected)\n",
    "platform_cols = [c for c in base.columns if c.startswith(\"most_used_\")]\n",
    "platform_names = [c.replace(\"most_used_\",\"\") for c in platform_cols]\n",
    "dim_platform = pd.DataFrame({\"platform_col\": platform_cols, \"platform\": platform_names})\n",
    "\n",
    "print(\"Dimension tables sizes: age:\", len(dim_age), \"gender:\", len(dim_gender),\n",
    "      \"platforms:\", len(dim_platform))\n",
    "\n",
    "# ---------- 11. Final: show outputs ----------\n",
    "# fact_student_summary (one row per age_group x gender) is your main fact table for visualizations\n",
    "# fact_cdc_age, fact_cdc_sex are CDC facts for reference\n",
    "# dims: dim_age_group, dim_gender, dim_degree, dim_department, dim_family_income, dim_platform, dim_relationship\n",
    "\n",
    "fact_student_summary.to_csv(\"fact_student_summary.csv\", index=False)\n",
    "fact_cdc_age.to_csv(\"fact_cdc_age.csv\", index=False)\n",
    "fact_cdc_sex.to_csv(\"fact_cdc_sex.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b271106",
   "metadata": {},
   "source": [
    "## 3. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0712ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'admin'\n",
    "password = 'root'\n",
    "host = 'localhost'          \n",
    "port = '3306'               \n",
    "database = 'olap_dashboard'  \n",
    "\n",
    "engine = create_engine(\"mysql+mysqlconnector://root:admin@localhost:3306/olap_dashboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b14d1870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading tables to MySQL...\n",
      "fact_student_summary: 58 rows\n",
      "fact_cdc_age: 0 rows\n",
      "fact_cdc_sex: 6 rows\n",
      "Load complete.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# 1) Read connection settings\n",
    "MYSQL_HOST = os.getenv(\"MYSQL_HOST\", \"localhost\")\n",
    "MYSQL_PORT = int(os.getenv(\"MYSQL_PORT\", \"3306\"))\n",
    "MYSQL_DB   = os.getenv(\"MYSQL_DB\", \"olap_dashboard\")\n",
    "MYSQL_USER = os.getenv(\"MYSQL_USER\", \"root\")\n",
    "MYSQL_PWD  = os.getenv(\"MYSQL_PASSWORD\", \"admin\")\n",
    "\n",
    "if not MYSQL_PWD:\n",
    "    raise RuntimeError(\"Missing MYSQL_PASSWORD. Put it in .env or export it in your terminal.\")\n",
    "\n",
    "# 2) Ensure database exists (connect to server without DB first)\n",
    "server_url = f\"mysql+pymysql://{MYSQL_USER}:{MYSQL_PWD}@{MYSQL_HOST}:{MYSQL_PORT}\"\n",
    "server_engine = create_engine(server_url, pool_pre_ping=True)\n",
    "\n",
    "with server_engine.connect() as conn:\n",
    "    conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS `{MYSQL_DB}` CHARACTER SET utf8mb4\"))\n",
    "    conn.commit()\n",
    "\n",
    "# 3) Connect to the specific DB\n",
    "db_url = f\"{server_url}/{MYSQL_DB}?charset=utf8mb4\"\n",
    "engine = create_engine(db_url, pool_pre_ping=True)\n",
    "\n",
    "# Helper: use in-memory DF if available, else load the CSV from disk\n",
    "def ensure_df(var_name: str, csv_path: str) -> pd.DataFrame:\n",
    "    if var_name in globals() and isinstance(globals()[var_name], pd.DataFrame):\n",
    "        return globals()[var_name]\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "# 4) Get data to load\n",
    "fact_student_summary_df = ensure_df(\"fact_student_summary\", \"fact_student_summary.csv\")\n",
    "fact_cdc_age_df         = ensure_df(\"fact_cdc_age\", \"fact_cdc_age.csv\")\n",
    "fact_cdc_sex_df         = ensure_df(\"fact_cdc_sex\", \"fact_cdc_sex.csv\")\n",
    "\n",
    "# Enforce key dtypes to match schema (age INT, gender VARCHAR, indicator VARCHAR)\n",
    "fact_student_summary_df[\"age\"] = pd.to_numeric(fact_student_summary_df[\"age\"], errors=\"coerce\").astype(\"Int64\")\n",
    "fact_student_summary_df[\"gender\"] = fact_student_summary_df[\"gender\"].astype(str).str.title()\n",
    "fact_student_summary_df = fact_student_summary_df.dropna(subset=[\"age\",\"gender\"])\n",
    "\n",
    "fact_cdc_age_df[\"age\"] = pd.to_numeric(fact_cdc_age_df[\"age\"], errors=\"coerce\").astype(\"Int64\")\n",
    "fact_cdc_age_df = fact_cdc_age_df.dropna(subset=[\"indicator\",\"age\"])\n",
    "fact_cdc_age_df[\"indicator\"] = fact_cdc_age_df[\"indicator\"].astype(str)\n",
    "\n",
    "fact_cdc_sex_df[\"gender\"] = fact_cdc_sex_df[\"gender\"].astype(str).str.title()\n",
    "fact_cdc_sex_df[\"indicator\"] = fact_cdc_sex_df[\"indicator\"].astype(str)\n",
    "fact_cdc_sex_df = fact_cdc_sex_df.dropna(subset=[\"indicator\",\"gender\"])\n",
    "\n",
    "# Set MySQL dtypes for key columns\n",
    "from sqlalchemy.types import Integer, String\n",
    "\n",
    "fss_dtypes = {\"age\": Integer(), \"gender\": String(16)}\n",
    "cdc_age_dtypes = {\"indicator\": String(128), \"age\": Integer()}\n",
    "cdc_sex_dtypes = {\"indicator\": String(128), \"gender\": String(16)}\n",
    "\n",
    "# 5) Write to MySQL (overwrite for repeatable runs; change to 'append' if preferred)\n",
    "print(\"Uploading tables to MySQL...\")\n",
    "fact_student_summary_df.to_sql(\n",
    "    \"fact_student_summary\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\", dtype=fss_dtypes\n",
    ")\n",
    "fact_cdc_age_df.to_sql(\n",
    "    \"fact_cdc_age\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\", dtype=cdc_age_dtypes\n",
    ")\n",
    "fact_cdc_sex_df.to_sql(\n",
    "    \"fact_cdc_sex\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\", dtype=cdc_sex_dtypes\n",
    ")\n",
    "\n",
    "# 6) Quick verification\n",
    "with engine.connect() as conn:\n",
    "    for tbl in (\"fact_student_summary\", \"fact_cdc_age\", \"fact_cdc_sex\"):\n",
    "        n = conn.execute(text(f\"SELECT COUNT(*) FROM `{tbl}`\")).scalar()\n",
    "        print(f\"{tbl}: {n} rows\")\n",
    "\n",
    "print(\"Load complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ce1f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_age: 42 rows\n",
      "dim_gender: 2 rows\n",
      "dim_platform: 12 rows\n",
      "Dimension load complete.\n"
     ]
    }
   ],
   "source": [
    "# 3. Load â€” dimensions\n",
    "\n",
    "required_dims = [\n",
    "    \"dim_age\",\"dim_gender\",\"dim_platform\",\n",
    "]\n",
    "missing = [d for d in required_dims if d not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing dimension dataframes: {missing}. Run Transform first.\")\n",
    "\n",
    "# Deduplicate\n",
    "dim_age        = dim_age.drop_duplicates(subset=[\"age\"]).sort_values(\"age\")\n",
    "dim_gender     = dim_gender.drop_duplicates(subset=[\"gender\"]).sort_values(\"gender\")\n",
    "dim_platform   = dim_platform.drop_duplicates(subset=[\"platform_col\",\"platform\"]).sort_values(\"platform\")\n",
    "\n",
    "# Write\n",
    "dim_age.to_sql(\"dim_age\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "dim_gender.to_sql(\"dim_gender\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "dim_platform.to_sql(\"dim_platform\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "\n",
    "# Verify\n",
    "with engine.connect() as conn:\n",
    "    for tbl in (\"dim_age\",\"dim_gender\",\"dim_platform\"):\n",
    "        n = conn.execute(text(f\"SELECT COUNT(*) FROM `{tbl}`\")).scalar()\n",
    "        print(f\"{tbl}: {n} rows\")\n",
    "\n",
    "print(\"Dimension load complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6ba953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys and constraints applied.\n"
     ]
    }
   ],
   "source": [
    "# Add primary/foreign keys after loads\n",
    "def run(sql):\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(text(sql))\n",
    "    except Exception as e:\n",
    "        print(\"Skip:\", e)\n",
    "\n",
    "# Dimension PKs\n",
    "run(\"ALTER TABLE dim_age MODIFY age INT NOT NULL;\")\n",
    "run(\"ALTER TABLE dim_age ADD PRIMARY KEY (age);\")\n",
    "\n",
    "run(\"ALTER TABLE dim_gender MODIFY gender VARCHAR(16) NOT NULL;\")\n",
    "run(\"ALTER TABLE dim_gender ADD PRIMARY KEY (gender);\")\n",
    "\n",
    "run(\"ALTER TABLE dim_platform MODIFY platform_col VARCHAR(64) NOT NULL;\")\n",
    "run(\"ALTER TABLE dim_platform ADD PRIMARY KEY (platform_col);\")\n",
    "\n",
    "# Fact keys/FKs\n",
    "run(\"ALTER TABLE fact_student_summary MODIFY age INT NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_student_summary MODIFY gender VARCHAR(16) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_student_summary ADD PRIMARY KEY (age, gender);\")\n",
    "run(\"\"\"\n",
    "ALTER TABLE fact_student_summary\n",
    "  ADD CONSTRAINT fk_fss_age FOREIGN KEY (age) REFERENCES dim_age(age)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT,\n",
    "  ADD CONSTRAINT fk_fss_gender FOREIGN KEY (gender) REFERENCES dim_gender(gender)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT;\n",
    "\"\"\")\n",
    "\n",
    "run(\"ALTER TABLE fact_cdc_age MODIFY indicator VARCHAR(128) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_age MODIFY age INT NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_age ADD PRIMARY KEY (indicator, age);\")\n",
    "run(\"\"\"\n",
    "ALTER TABLE fact_cdc_age\n",
    "  ADD CONSTRAINT fk_cdc_age_age FOREIGN KEY (age) REFERENCES dim_age(age)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT;\n",
    "\"\"\")\n",
    "\n",
    "# fact_cdc_sex(indicator, gender)\n",
    "run(\"ALTER TABLE fact_cdc_sex MODIFY indicator VARCHAR(128) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_sex MODIFY gender VARCHAR(16) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_sex ADD PRIMARY KEY (indicator, gender);\")\n",
    "run(\"\"\"\n",
    "ALTER TABLE fact_cdc_sex\n",
    "  ADD CONSTRAINT fk_cdc_sex_gender FOREIGN KEY (gender) REFERENCES dim_gender(gender)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT;\n",
    "\"\"\")\n",
    "\n",
    "print(\"Keys and constraints applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d44c2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = {\n",
    "    \"dim_age\": dim_age,\n",
    "    \"dim_gender\": dim_gender,\n",
    "    \"dim_platform\": dim_platform,\n",
    "}\n",
    "for name, df in dims.items():\n",
    "    df.to_csv(f\"{name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
