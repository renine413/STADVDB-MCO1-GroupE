{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b08927",
   "metadata": {},
   "source": [
    "# ETL Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5dff2",
   "metadata": {},
   "source": [
    "## 1. Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a45fc",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29bb4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4124f",
   "metadata": {},
   "source": [
    "Read datasets:\n",
    "1. Indicators of Anxiety or Depression Based on Reported Frequency of Symptoms During Last 7 Days\n",
    "2. Student Depression Dataset\n",
    "3. Student Mental Health Crisis After COVID-19\n",
    "4. Student Performance and Behavior Dataset\n",
    "5. Students Social Media Addiction Dataset\n",
    "6. PHQ-9 Student Depression Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6804be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json(\"datasets/cdc-indicators-of-anxiety-or-depression.json\")\n",
    "df2 = pd.read_csv(\"datasets/kaggle-student-depression-dataset.csv\")\n",
    "df3 = pd.read_excel(\"datasets/kaggle-student-mental-health-crisis-after-covid19-final.xlsx\")\n",
    "df4 = pd.read_json(\"datasets/kaggle-student-performance-and-behavior-dataset.json\")\n",
    "df5 = pd.read_csv(\"datasets/kaggle-students-social-media-addiction.csv\")\n",
    "df6 = pd.read_csv(\"datasets/mendeley-phq9-student-depression-dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaed702",
   "metadata": {},
   "source": [
    "## 2. Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3946b",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1ad28",
   "metadata": {},
   "source": [
    "1. Rename columns for clarity and consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c409f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = [\"indicator\", \"grp\", \"state\", \"subgroup\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"value\", \"low_CI\", \"high_CI\", \"confidence_interval\", \"quartile_range\"]\n",
    "df2.columns = [\"id\", \"gender\", \"age\", \"city\", \"profession\", \"academic_pressure\", \"work_pressure\", \"cgpa\", \"study_satisfaction\", \"job_satisfaction\", \"sleep_duration\", \"dietary_habits\", \"degree\", \"has_suicidal_thoughts\", \"work_study_hours\", \"financial_stress\", \"has_family_mental_illness\", \"has_depression\"]\n",
    "df3.columns = [\"gender\", \"age\", \"city\", \"profession\", \"academic_pressure\", \"work_pressure\", \"cgpa\", \"study_satisfaction\", \"job_satisfaction\", \"sleep_duration\", \"dietary_habits\", \"degree\", \"has_suicidal_thoughts\", \"work_study_hours\", \"financial_stress\", \"has_family_mental_illness\", \"has_depression\"]\n",
    "df4.columns = [\"student_id\", \"first_name\", \"last_name\", \"email\", \"gender\", \"age\", \"department\", \"attendance\", \"midterm_score\", \"final_score\", \"assignments_ave\", \"quizzes_ave\", \"participation_score\", \"projects_score\", \"total_score\", \"grade\", \"study_hours_per_week\", \"has_extracurricular\", \"has_internet_access\", \"parent_education_level\", \"family_income_level\", \"stress_level\", \"sleep_hours\"]\n",
    "df5.columns = [\"student_id\", \"age\", \"gender\", \"academic_level\", \"country\", \"ave_daily_usage_hours\", \"most_used_platform\", \"affects_academic_performance\", \"sleep_hours\", \"mental_health_score\", \"relationship_status\", \"conflicts_over_social_media\", \"addicted_score\"] \n",
    "df6.columns = ['age','gender','interest_loss','depressed_mood','sleep_trouble','fatigue','appetite_change','guilt_failure','concentration','fidgety_restless','suicidal_thoughts','phq9_score','depression_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf97498",
   "metadata": {},
   "source": [
    "2. Split DF1 into two dataframes based on gender and age groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "855f4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1[\"grp\"].isin([\"By Age\", \"By Sex\"])]\n",
    "df1_age = df1[df1[\"grp\"] == \"By Age\"].copy()\n",
    "df1_sex = df1[df1[\"grp\"] == \"By Sex\"].copy()\n",
    "df1_age = df1_age.rename(columns={\"subgroup\": \"age\"})\n",
    "df1_sex = df1_sex.rename(columns={\"subgroup\": \"gender\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f7ee9f",
   "metadata": {},
   "source": [
    "3. Drop unnecessary columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e89e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age = df1_age.drop(columns=[\"grp\", \"state\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"quartile_range\"])\n",
    "df1_sex = df1_sex.drop(columns=[\"grp\", \"state\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"quartile_range\"])\n",
    "df2 = df2.drop(columns=[\"id\", \"city\", \"profession\", \"work_pressure\", \"job_satisfaction\"])\n",
    "df3 = df3.drop(columns=[\"city\", \"profession\", \"work_pressure\", \"job_satisfaction\"])\n",
    "df4 = df4.drop(columns=[\"student_id\", \"first_name\", \"last_name\", \"email\", \"grade\"])\n",
    "df5 = df5.drop(columns=[\"student_id\", \"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5e6f6",
   "metadata": {},
   "source": [
    "4. Drop rows with exceeding age groups and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742a5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age = df1_age[~df1_age[\"age\"].isin(['60 - 69 years', '70 - 79 years', '80 years and above'])]\n",
    "df4 = df4.dropna(subset=[\"attendance\", \"assignments_ave\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264786d",
   "metadata": {},
   "source": [
    "5. Fill missing values with mean and default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fbf47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"financial_stress\"] = df2[\"financial_stress\"].fillna(df2[\"financial_stress\"].mean())\n",
    "df4[\"parent_education_level\"] = df4[\"parent_education_level\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459c874",
   "metadata": {},
   "source": [
    "### Data Type Normalization and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248a3dc",
   "metadata": {},
   "source": [
    "1. Convert age from float to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "047e9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"age\"] = df2[\"age\"].fillna(df2[\"age\"].median()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6986f",
   "metadata": {},
   "source": [
    "2. Convert confidence interval values to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a96111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age['value'] = pd.to_numeric(df1_age['value'], errors='coerce')\n",
    "df1_age['low_CI'] = pd.to_numeric(df1_age['low_CI'], errors='coerce')\n",
    "df1_age['high_CI'] = pd.to_numeric(df1_age['high_CI'], errors='coerce')\n",
    "\n",
    "df1_sex['value'] = pd.to_numeric(df1_sex['value'], errors='coerce')\n",
    "df1_sex['low_CI'] = pd.to_numeric(df1_sex['low_CI'], errors='coerce')\n",
    "df1_sex['high_CI'] = pd.to_numeric(df1_sex['high_CI'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0304bc",
   "metadata": {},
   "source": [
    "3. Convert boolean columns from 'Yes'/'No' to 1/0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dad8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_columns = {\n",
    "    'df2': [\"has_suicidal_thoughts\", \"has_family_mental_illness\"],\n",
    "    'df3': [\"has_suicidal_thoughts\", \"has_family_mental_illness\", \"has_depression\"],\n",
    "    'df4': [\"has_extracurricular\", \"has_internet_access\"],\n",
    "    'df5': [\"affects_academic_performance\"],\n",
    "}\n",
    "\n",
    "for df_name, columns in bool_columns.items():\n",
    "    df = globals()[df_name]\n",
    "    for col in columns:\n",
    "        df[col] = df[col].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c50a8",
   "metadata": {},
   "source": [
    "4. Map sleep hours to average values in DF2 and DF3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015a9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_map = {\n",
    "    'Less than 5 hours': 4.5,\n",
    "    '5-6 hours': 5.5,\n",
    "    '7-8 hours': 7.5,\n",
    "    'More than 8 hours': 9,\n",
    "    'Others': None\n",
    "}\n",
    "df2['sleep_duration'] = df2['sleep_duration'].map(sleep_map)\n",
    "df3['sleep_duration'] = df3['sleep_duration'].map(sleep_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871e570",
   "metadata": {},
   "source": [
    "5. Map survery response and depresssion levels to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1d61b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_cols = [\n",
    "    'interest_loss',\n",
    "    'depressed_mood',\n",
    "    'sleep_trouble',\n",
    "    'fatigue',\n",
    "    'appetite_change',\n",
    "    'guilt_failure',\n",
    "    'concentration',\n",
    "    'fidgety_restless',\n",
    "    'suicidal_thoughts'\n",
    "]\n",
    "\n",
    "depression_mapping = {\n",
    "    'Minimal': 0,\n",
    "    'Mild': 1,\n",
    "    'Moderate': 2,\n",
    "    'Moderately Severe': 3,\n",
    "    'Severe': 4\n",
    "}\n",
    "\n",
    "mapping = {\n",
    "    'Not at all': 0,\n",
    "    'Several days': 1,\n",
    "    'More than half the days': 2,\n",
    "    'Nearly every day': 3\n",
    "}\n",
    "\n",
    "df6[survey_cols] = df6[survey_cols].apply(lambda col: col.map(mapping))\n",
    "df6['depression_level'] = df6['depression_level'].map(depression_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39cc5d",
   "metadata": {},
   "source": [
    "6. Apply one-hot encoding to categorical columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "025f68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dietary_habits from DF2 and DF3\n",
    "df2 = pd.concat([df2, pd.get_dummies(df2['dietary_habits'], prefix='diet')], axis=1)\n",
    "df3 = pd.concat([df3, pd.get_dummies(df3['dietary_habits'], prefix='diet')], axis=1)\n",
    "df2.drop(columns=['dietary_habits'], inplace=True)\n",
    "df3.drop(columns=['dietary_habits'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3803b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_used_platform, academic_level, and relationship_status from DF5\n",
    "# Create cleaned dummies and aggregate DF5 to get proportions per (age, gender)\n",
    "df5['most_used_platform'] = df5.get('most_used_platform', '').astype(str).str.strip()\n",
    "df5['relationship_status'] = df5.get('relationship_status', '').astype(str).str.strip()\n",
    "df5['academic_level'] = df5.get('academic_level', '').astype(str).str.strip()\n",
    "\n",
    "# one-hot\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['most_used_platform'], prefix='most_used')], axis=1)\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['relationship_status'], prefix='rel_status')], axis=1)\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['academic_level'], prefix='academic_level')], axis=1)\n",
    "df5.drop(columns=['most_used_platform', 'relationship_status', 'academic_level'], inplace=True, errors='ignore')\n",
    "\n",
    "# numeric columns we care about in DF5\n",
    "df5_num = [c for c in ['ave_daily_usage_hours','affects_academic_performance','sleep_hours','mental_health_score','conflicts_over_social_media','addicted_score'] if c in df5.columns]\n",
    "\n",
    "# collect df5 one-hot columns\n",
    "df5_onehots = [c for c in df5.columns if c.startswith(('most_used_','rel_status_','academic_level_'))]\n",
    "\n",
    "# coerce numeric\n",
    "for c in df5_num:\n",
    "    df5[c] = pd.to_numeric(df5[c], errors='coerce')\n",
    "\n",
    "# Aggregate DF5 by age,gender -> numeric means + one-hot means (fractions)\n",
    "agg_cols = df5_num + df5_onehots\n",
    "if agg_cols:\n",
    "    df5_agg = df5.groupby(['age','gender'], as_index=False)[agg_cols].mean()\n",
    "else:\n",
    "    df5_agg = df5.drop_duplicates(subset=['age','gender'])[['age','gender']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f31af",
   "metadata": {},
   "source": [
    "### Aggregates and Normalization to Fact Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b3160c",
   "metadata": {},
   "source": [
    "Set the minimum and maximum values for the ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f46a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_MIN = 18\n",
    "AGE_MAX = 59"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbe236",
   "metadata": {},
   "source": [
    "Helper functions to:\n",
    "- Normalize column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b151c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_cols(df):\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_', regex=False)\n",
    "        .str.replace(r'[^0-9a-zA-Z_]', '', regex=True)\n",
    "        .str.replace('__', '_', regex=False)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac2c991",
   "metadata": {},
   "source": [
    "- Make a copy and safely explode df1_age into finer groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca57d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_cdc_age_to_ages(df_age):\n",
    "    import re\n",
    "    df = df_age.copy()\n",
    "    def parse_range(s):\n",
    "        s = str(s)\n",
    "        m = re.search(r\"(\\d+)\\s*-\\s*(\\d+)\", s)\n",
    "        if not m:\n",
    "            return None\n",
    "        lo, hi = int(m.group(1)), int(m.group(2))\n",
    "        return list(range(lo, hi + 1))\n",
    "    df[\"ages\"] = df[\"age\"].map(parse_range)\n",
    "    df = df[df[\"ages\"].notna()].copy()\n",
    "    df = df.explode(\"ages\").rename(columns={\"ages\":\"age\"})\n",
    "    df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df = df[(df[\"age\"] >= AGE_MIN) & (df[\"age\"] <= AGE_MAX)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ea102d",
   "metadata": {},
   "source": [
    "1. Normalize column names for all the dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ac1a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age = normalize_cols(df1_age)\n",
    "df1_sex = normalize_cols(df1_sex)\n",
    "df2 = normalize_cols(df2)\n",
    "df3 = normalize_cols(df3)\n",
    "df4 = normalize_cols(df4)\n",
    "df5 = normalize_cols(df5)\n",
    "df6 = normalize_cols(df6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d0ca9",
   "metadata": {},
   "source": [
    "2. Ensure age is numeric and within allowed range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e42d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dfn in (\"df2\",\"df3\",\"df4\",\"df5\",\"df6\"):\n",
    "    df = globals()[dfn]\n",
    "    df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\").round().astype(\"Int64\")\n",
    "    df[\"age\"] = df[\"age\"].where((df[\"age\"] >= AGE_MIN) & (df[\"age\"] <= AGE_MAX))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dcff11",
   "metadata": {},
   "source": [
    "3. Clean and convert CDC (df1_age, df1_sex) to numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bcba5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (df1_age, df1_sex):\n",
    "    for col in ['value','low_ci','high_ci']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e57de",
   "metadata": {},
   "source": [
    "- Drop CDC rows outside 18-59 for df1_age and split ranges into two subgroups (18-24,25-29)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dce9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_mapping = {\n",
    "    '18 - 29 years': ['18-24','25-29'],\n",
    "    '30 - 39 years': ['30-34','35-39'],\n",
    "    '40 - 49 years': ['40-44','45-49'],\n",
    "    '50 - 59 years': ['50-54','55-59']\n",
    "}\n",
    "\n",
    "try:\n",
    "    cdc_age_expanded = expand_cdc_age_to_ages(df1_age)\n",
    "except Exception:\n",
    "    cdc_age_expanded = df1_age.copy()\n",
    "    cdc_age_expanded['age_group'] = cdc_age_expanded['age'].map({\n",
    "        '18 - 29 years':'18-24', '30 - 39 years':'30-39', '40 - 49 years':'40-49', '50 - 59 years':'50-59'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aae01d",
   "metadata": {},
   "source": [
    "- Normalize gender names for df1_sex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b4bfbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_sex['gender'] = (df1_sex['gender'].astype(str)\n",
    "                     .str.strip().str.lower().replace({'male':'male','female':'female'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b8d95",
   "metadata": {},
   "source": [
    "- Canonicalize to capitalized or lower consistently; we'll use title case in final dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "302de0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_sex['gender'] = df1_sex['gender'].str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223dc95f",
   "metadata": {},
   "source": [
    "4. Prepare one-hot column lists (predictable after normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4249da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_prefixes = ('diet_', 'most_used_', 'rel_status_', 'academic_level_')\n",
    "one_hot_cols = [col for col in pd.concat([df2, df3, df5], ignore_index=True).columns\n",
    "                if col.startswith(onehot_prefixes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd23424f",
   "metadata": {},
   "source": [
    "- Remove duplicates and ensure existence in combined fact_student later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dac44329",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols = sorted(set(one_hot_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a48081a",
   "metadata": {},
   "source": [
    "5. Build combined student table but avoid creating monstrous intermediate objects.\n",
    "- Merge carefully and then select columns that will be aggregated.\n",
    "- Normalize merge keys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33748609",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (df2, df3, df4, df5, df6):\n",
    "    df['gender'] = df['gender'].astype(str).str.strip().str.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a131eb",
   "metadata": {},
   "source": [
    "- Start with df2 as base (individual-level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d66d189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569b0d4a",
   "metadata": {},
   "source": [
    "- When merging df3, drop columns that are duplicates in base to avoid wide duplication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa18db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_from_df3 = [c for c in ['degree','sleep_duration','diet_healthy','diet_moderate','diet_unhealthy'] if c in df3.columns]\n",
    "df3_for_merge = df3.drop(columns=cols_to_drop_from_df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c74df25",
   "metadata": {},
   "source": [
    "- Merge step-by-step; keep only needed columns to reduce memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ad113ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = base.merge(df3_for_merge, on=['age','gender'], how='left', suffixes=('','_df3'))\n",
    "\n",
    "# Merge df4: keep numeric/performance columns + department/parent_education_level/family_income_level\n",
    "df4_keep = [c for c in ['attendance','midterm_score','final_score','assignments_ave','quizzes_ave',\n",
    "                        'participation_score','projects_score','total_score','study_hours_per_week',\n",
    "                        'has_extracurricular','has_internet_access','parent_education_level',\n",
    "                        'family_income_level','department','stress_level','sleep_hours'] if c in df4.columns]\n",
    "base = base.merge(df4[df4_keep + ['age','gender']].drop_duplicates(subset=['age','gender']), on=['age','gender'], how='left')\n",
    "\n",
    "# Merge df5 aggregated (proportions) into base\n",
    "df5_keep = [c for c in df5_agg.columns if c not in ['age','gender']]\n",
    "base = base.merge(\n",
    "    df5_agg[['age','gender'] + df5_keep].drop_duplicates(subset=['age','gender']),\n",
    "    on=['age','gender'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge df6: survey and phq9 score\n",
    "df6_keep = [c for c in ['interest_loss','depressed_mood','sleep_trouble','fatigue','appetite_change',\n",
    "                        'guilt_failure','concentration','fidgety_restless','suicidal_thoughts','phq9_score','depression_level','age','gender'] if c in df6.columns]\n",
    "base = base.merge(df6[df6_keep].drop_duplicates(subset=['age','gender']), on=['age','gender'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0dead",
   "metadata": {},
   "source": [
    "6. Identify numeric and one-hot columns for aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7729bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns: numbers and bools (coerce non-numeric to NaN)\n",
    "numeric_candidates = base.select_dtypes(include=['number','bool']).columns.tolist()\n",
    "\n",
    "# Some numeric-like columns may still be object due to NaNs; coerce those we expect to be numeric\n",
    "to_float_try = ['cgpa','academic_pressure','study_satisfaction','work_study_hours','financial_stress',\n",
    "                'attendance','midterm_score','final_score','assignments_ave','quizzes_ave','participation_score',\n",
    "                'projects_score','total_score','study_hours_per_week','stress_level','sleep_hours',\n",
    "                'ave_daily_usage_hours','mental_health_score','conflicts_over_social_media','addicted_score',\n",
    "                'phq9_score']\n",
    "for c in to_float_try:\n",
    "    if c in base.columns:\n",
    "        base[c] = pd.to_numeric(base[c], errors='coerce')\n",
    "\n",
    "# Now recompute numeric columns\n",
    "numeric_cols = [c for c in base.select_dtypes(include=['number','bool','float','int']).columns if c not in ['age']]\n",
    "\n",
    "# Exclude one-hot cols from numeric_cols (we will aggregate them separately)\n",
    "one_hot_cols = [c for c in base.columns if (\n",
    "    c.startswith('diet_') or c.startswith('most_used_') or c.startswith('rel_status_') or c.startswith('academic_level_')\n",
    ")]\n",
    "numeric_non_onehot = [c for c in numeric_cols if c not in one_hot_cols]\n",
    "\n",
    "# Convert numeric_non_onehot to float32 to save memory\n",
    "for c in numeric_non_onehot:\n",
    "    try:\n",
    "        base[c] = base[c].astype('float32')\n",
    "    except Exception:\n",
    "        base[c] = pd.to_numeric(base[c], errors='coerce').astype('float32')\n",
    "\n",
    "# Convert one-hot columns to float32 as well (they are 0/1)\n",
    "for c in one_hot_cols:\n",
    "    base[c] = pd.to_numeric(base[c], errors='coerce').fillna(0).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c47458b",
   "metadata": {},
   "source": [
    "7. Aggregate (memory-safe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "152de70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cols = [\"age\",\"gender\"]\n",
    "\n",
    "# (A) Numeric non-onehot aggregation\n",
    "numeric_summary = base.groupby(group_cols, as_index=False)[numeric_non_onehot].mean()\n",
    "\n",
    "# (B) One-hot aggregation\n",
    "if one_hot_cols:\n",
    "    onehot_summary = base.groupby(group_cols, as_index=False)[one_hot_cols].mean()\n",
    "    fact_student_summary = pd.merge(numeric_summary, onehot_summary, on=group_cols, how=\"outer\")\n",
    "else:\n",
    "    fact_student_summary = numeric_summary\n",
    "\n",
    "# Rename numeric aggregates\n",
    "rename_map = {c: (\"avg_\" + c) for c in numeric_non_onehot}\n",
    "fact_student_summary.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Keep valid ages only\n",
    "fact_student_summary = fact_student_summary[\n",
    "    fact_student_summary[\"age\"].between(AGE_MIN, AGE_MAX)\n",
    "].sort_values([\"age\",\"gender\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be886d8d",
   "metadata": {},
   "source": [
    "8. Postprocess fact_student_summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f1c7028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact student summary shape: (58, 71)\n",
      "   age  gender  avg_academic_pressure  avg_cgpa  avg_study_satisfaction  \\\n",
      "0   18  Female               3.522059  7.474971                3.307353   \n",
      "1   18    Male               3.506064  7.609262                3.159868   \n",
      "2   19  Female               3.287729  7.588110                3.119887   \n",
      "3   19    Male               3.310223  7.725241                2.968273   \n",
      "4   20  Female               3.372567  7.557442                3.077850   \n",
      "\n",
      "   avg_sleep_duration  avg_has_suicidal_thoughts  avg_work_study_hours  \\\n",
      "0            6.528718                   0.732353              7.447059   \n",
      "1            6.474642                   0.683572              7.223815   \n",
      "2            6.519746                   0.691114              7.224259   \n",
      "3            6.552291                   0.707403              7.316099   \n",
      "4            6.521316                   0.713624              7.060241   \n",
      "\n",
      "   avg_financial_stress  avg_has_family_mental_illness  ...  \\\n",
      "0              3.288235                       0.488235  ...   \n",
      "1              3.264609                       0.468578  ...   \n",
      "2              3.181947                       0.492243  ...   \n",
      "3              3.265570                       0.508813  ...   \n",
      "4              3.396793                       0.518999  ...   \n",
      "\n",
      "   most_used_VKontakte  most_used_WeChat  most_used_WhatsApp  \\\n",
      "0                  0.0          0.000000            0.000000   \n",
      "1                  0.0          0.000000            0.000000   \n",
      "2                  0.0          0.007407            0.059259   \n",
      "3                  0.0          0.035714            0.000000   \n",
      "4                  0.0          0.000000            0.020548   \n",
      "\n",
      "   most_used_YouTube  rel_status_Complicated  rel_status_In Relationship  \\\n",
      "0           0.000000                0.200000                    0.000000   \n",
      "1           0.111111                0.111111                    0.111111   \n",
      "2           0.000000                0.044444                    0.303704   \n",
      "3           0.035714                0.214286                    0.214286   \n",
      "4           0.000000                0.047945                    0.404110   \n",
      "\n",
      "   rel_status_Single  academic_level_Graduate  academic_level_High School  \\\n",
      "0           0.800000                      0.0                    1.000000   \n",
      "1           0.777778                      0.0                    1.000000   \n",
      "2           0.651852                      0.0                    0.059259   \n",
      "3           0.571429                      0.0                    0.107143   \n",
      "4           0.547945                      0.0                    0.013699   \n",
      "\n",
      "   academic_level_Undergraduate  \n",
      "0                      0.000000  \n",
      "1                      0.000000  \n",
      "2                      0.940741  \n",
      "3                      0.892857  \n",
      "4                      0.986301  \n",
      "\n",
      "[5 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "group_cols = [\"age\",\"gender\"]\n",
    "\n",
    "# (A) Numeric non-onehot aggregation\n",
    "numeric_summary = base.groupby(group_cols, as_index=False)[numeric_non_onehot].mean()\n",
    "\n",
    "# (B) One-hot aggregation\n",
    "if one_hot_cols:\n",
    "    onehot_summary = base.groupby(group_cols, as_index=False)[one_hot_cols].mean()\n",
    "    fact_student_summary = pd.merge(numeric_summary, onehot_summary, on=group_cols, how=\"outer\")\n",
    "else:\n",
    "    fact_student_summary = numeric_summary\n",
    "\n",
    "# Rename numeric aggregates\n",
    "rename_map = {c: (\"avg_\" + c) for c in numeric_non_onehot}\n",
    "fact_student_summary.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# Keep valid ages only\n",
    "fact_student_summary = fact_student_summary[\n",
    "    fact_student_summary[\"age\"].between(AGE_MIN, AGE_MAX)\n",
    "].sort_values([\"age\",\"gender\"]).reset_index(drop=True)\n",
    "\n",
    "# Rename aggregates to show they are group-level means\n",
    "rename_map = {c: ('avg_' + c) for c in numeric_non_onehot}\n",
    "fact_student_summary.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# one-hot columns represent fractions/proportions\n",
    "fact_student_summary = fact_student_summary.sort_values(['age','gender']).reset_index(drop=True)\n",
    "\n",
    "print(\"Fact student summary shape:\", fact_student_summary.shape)\n",
    "print(fact_student_summary.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0285e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c96e0cb5",
   "metadata": {},
   "source": [
    "9. Build CDC fact tables (age and sex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d1d146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact CDC age shape: (12, 5)\n",
      "Fact CDC sex shape: (6, 5)\n"
     ]
    }
   ],
   "source": [
    "# df1_age expanded -> cdc_age_expanded already built above\n",
    "# aggregate by indicator, age_group\n",
    "fact_cdc_age = (cdc_age_expanded\n",
    "                .groupby([\"indicator\",\"age\"], as_index=False)\n",
    "                .agg({\"value\":\"mean\",\"low_ci\":\"mean\",\"high_ci\":\"mean\"}))\n",
    "\n",
    "# df1_sex: normalize gender, aggregate by indicator, gender\n",
    "df1_sex[\"gender\"] = df1_sex[\"gender\"].str.title()\n",
    "fact_cdc_sex = (df1_sex\n",
    "                .groupby([\"indicator\",\"gender\"], as_index=False)\n",
    "                .agg({\"value\":\"mean\",\"low_ci\":\"mean\",\"high_ci\":\"mean\"}))\n",
    "\n",
    "print(\"Fact CDC age shape:\", fact_cdc_age.shape)\n",
    "print(\"Fact CDC sex shape:\", fact_cdc_sex.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769aa6bb",
   "metadata": {},
   "source": [
    "10. Build simple dimension tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c842ac44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension tables sizes: age: 42 gender: 2\n"
     ]
    }
   ],
   "source": [
    "dim_age = pd.DataFrame({\"age\": list(range(AGE_MIN, AGE_MAX + 1))})\n",
    "dim_gender = pd.DataFrame({\"gender\": sorted(fact_student_summary[\"gender\"].dropna().unique())})\n",
    "\n",
    "\n",
    "print(\"Dimension tables sizes: age:\", len(dim_age), \"gender:\", len(dim_gender))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98cd06",
   "metadata": {},
   "source": [
    "11. Show outputs:\n",
    "- fact_student_summary (one row per age_group x gender) is your main fact table for visualizations\n",
    "- fact_cdc_age, fact_cdc_sex are CDC facts for reference\n",
    "- dims: dim_age_group, dim_gender, dim_degree, dim_department, dim_family_income, dim_platform, dim_relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "343b6b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_student_summary.to_csv(\"fact_student_summary.csv\", index=False)\n",
    "fact_cdc_age.to_csv(\"fact_cdc_age.csv\", index=False)\n",
    "fact_cdc_sex.to_csv(\"fact_cdc_sex.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b271106",
   "metadata": {},
   "source": [
    "## 3. Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b00ce",
   "metadata": {},
   "source": [
    "Helper for using in-memory DF if available, else load the CSV from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de2dcb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_df(var_name: str, csv_path: str) -> pd.DataFrame:\n",
    "    if var_name in globals() and isinstance(globals()[var_name], pd.DataFrame):\n",
    "        return globals()[var_name]\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0712ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'root'\n",
    "password = 'password'\n",
    "host = 'localhost'          \n",
    "port = '3306'               \n",
    "database = 'olap_dashboard'  \n",
    "\n",
    "engine = create_engine(\"mysql+mysqlconnector://root:password@localhost:3306/olap_dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0513efd",
   "metadata": {},
   "source": [
    "1) Read connection settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f16accbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "MYSQL_HOST = os.getenv(\"MYSQL_HOST\", \"localhost\")\n",
    "MYSQL_PORT = int(os.getenv(\"MYSQL_PORT\", \"3306\"))\n",
    "MYSQL_DB   = os.getenv(\"MYSQL_DB\", \"olap_dashboard\")\n",
    "MYSQL_USER = os.getenv(\"MYSQL_USER\", \"root\")\n",
    "MYSQL_PWD  = os.getenv(\"MYSQL_PASSWORD\", \"password\")\n",
    "\n",
    "if not MYSQL_PWD:\n",
    "    raise RuntimeError(\"Missing MYSQL_PASSWORD. Put it in .env or export it in your terminal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea7c23",
   "metadata": {},
   "source": [
    "2) Ensure database exists (connect to server without DB first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4d9517a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(pymysql.err.OperationalError) (1045, \"Access denied for user 'root'@'localhost' (using password: YES)\")\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\engine\\base.py:143\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\engine\\base.py:3301\u001b[39m, in \u001b[36mEngine.raw_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[32m   3281\u001b[39m \n\u001b[32m   3282\u001b[39m \u001b[33;03mThe returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3299\u001b[39m \n\u001b[32m   3300\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:447\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[32m    441\u001b[39m \n\u001b[32m    442\u001b[39m \u001b[33;03mThe connection is instrumented such that when its\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m \n\u001b[32m    446\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:1264\u001b[39m, in \u001b[36m_ConnectionFairy._checkout\u001b[39m\u001b[34m(cls, pool, threadconns, fairy)\u001b[39m\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     fairy = \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1266\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:711\u001b[39m, in \u001b[36m_ConnectionRecord.checkout\u001b[39m\u001b[34m(cls, pool)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m     rec = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\impl.py:177\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\util\\langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\impl.py:175\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:388\u001b[39m, in \u001b[36mPool._create_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    386\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:673\u001b[39m, in \u001b[36m_ConnectionRecord.__init__\u001b[39m\u001b[34m(self, pool, connect)\u001b[39m\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[38;5;28mself\u001b[39m.finalize_callback = deque()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:899\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\util\\langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:895\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    894\u001b[39m \u001b[38;5;28mself\u001b[39m.starttime = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m \u001b[38;5;28mself\u001b[39m.dbapi_connection = connection = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m pool.logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\engine\\create.py:661\u001b[39m, in \u001b[36mcreate_engine.<locals>.connect\u001b[39m\u001b[34m(connection_record)\u001b[39m\n\u001b[32m    659\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\engine\\default.py:629\u001b[39m, in \u001b[36mDefaultDialect.connect\u001b[39m\u001b[34m(self, *cargs, **cparams)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cargs: Any, **cparams: Any) -> DBAPIConnection:\n\u001b[32m    628\u001b[39m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_dbapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:365\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_key_password, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[39m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:681\u001b[39m, in \u001b[36mConnection.connect\u001b[39m\u001b[34m(self, sock)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28mself\u001b[39m._get_server_information()\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_authentication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;66;03m# Send \"SET NAMES\" query on init for:\u001b[39;00m\n\u001b[32m    684\u001b[39m \u001b[38;5;66;03m# - Ensure charaset (and collation) is set to the server.\u001b[39;00m\n\u001b[32m    685\u001b[39m \u001b[38;5;66;03m#   - collation_id in handshake packet may be ignored.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    694\u001b[39m \u001b[38;5;66;03m# - https://github.com/wagtail/wagtail/issues/9477\u001b[39;00m\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# - https://zenn.dev/methane/articles/2023-mysql-collation (Japanese)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:980\u001b[39m, in \u001b[36mConnection._request_authentication\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    979\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._auth_plugin_name == \u001b[33m\"\u001b[39m\u001b[33mcaching_sha2_password\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     auth_packet = \u001b[43m_auth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaching_sha2_password_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_packet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._auth_plugin_name == \u001b[33m\"\u001b[39m\u001b[33msha256_password\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\_auth.py:272\u001b[39m, in \u001b[36mcaching_sha2_password_auth\u001b[39m\u001b[34m(conn, pkt)\u001b[39m\n\u001b[32m    271\u001b[39m data = sha2_rsa_encrypt(conn.password, conn.salt, conn.server_public_key)\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m pkt = \u001b[43m_roundtrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\_auth.py:121\u001b[39m, in \u001b[36m_roundtrip\u001b[39m\u001b[34m(conn, send_data)\u001b[39m\n\u001b[32m    120\u001b[39m conn.write_packet(send_data)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m pkt = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m pkt.check_error()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:782\u001b[39m, in \u001b[36mConnection._read_packet\u001b[39m\u001b[34m(self, packet_type)\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[38;5;28mself\u001b[39m._result.unbuffered_active = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m     \u001b[43mpacket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\protocol.py:219\u001b[39m, in \u001b[36mMysqlPacket.raise_for_error\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33merrno =\u001b[39m\u001b[33m\"\u001b[39m, errno)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m \u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\err.py:150\u001b[39m, in \u001b[36mraise_mysql_exception\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    149\u001b[39m     errorclass = InternalError \u001b[38;5;28;01mif\u001b[39;00m errno < \u001b[32m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[31mOperationalError\u001b[39m: (1045, \"Access denied for user 'root'@'localhost' (using password: YES)\")",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m server_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmysql+pymysql://\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMYSQL_USER\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMYSQL_PWD\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m@\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMYSQL_HOST\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMYSQL_PORT\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m server_engine = create_engine(server_url, pool_pre_ping=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mserver_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m      5\u001b[39m     conn.execute(text(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCREATE DATABASE IF NOT EXISTS `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMYSQL_DB\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` CHARACTER SET utf8mb4\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m      6\u001b[39m     conn.commit()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\engine\\base.py:3277\u001b[39m, in \u001b[36mEngine.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3254\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Connection:\n\u001b[32m   3255\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a new :class:`_engine.Connection` object.\u001b[39;00m\n\u001b[32m   3256\u001b[39m \n\u001b[32m   3257\u001b[39m \u001b[33;03m    The :class:`_engine.Connection` acts as a Python context manager, so\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3274\u001b[39m \n\u001b[32m   3275\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\engine\\base.py:145\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    143\u001b[39m         \u001b[38;5;28mself\u001b[39m._dbapi_connection = engine.raw_connection()\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m         \u001b[43mConnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception_noconnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\engine\\base.py:2440\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception_noconnection\u001b[39m\u001b[34m(cls, e, dialect, engine, is_disconnect, invalidate_pool_on_disconnect, is_pre_ping)\u001b[39m\n\u001b[32m   2438\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2439\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2440\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2441\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2442\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\engine\\base.py:143\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, engine, connection, _has_events, _allow_revalidate, _allow_autobegin)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         \u001b[38;5;28mself\u001b[39m._dbapi_connection = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraw_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m dialect.loaded_dbapi.Error \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    145\u001b[39m         Connection._handle_dbapi_exception_noconnection(\n\u001b[32m    146\u001b[39m             err, dialect, engine\n\u001b[32m    147\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\engine\\base.py:3301\u001b[39m, in \u001b[36mEngine.raw_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3279\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mraw_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> PoolProxiedConnection:\n\u001b[32m   3280\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a \"raw\" DBAPI connection from the connection pool.\u001b[39;00m\n\u001b[32m   3281\u001b[39m \n\u001b[32m   3282\u001b[39m \u001b[33;03m    The returned object is a proxied version of the DBAPI\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3299\u001b[39m \n\u001b[32m   3300\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3301\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:447\u001b[39m, in \u001b[36mPool.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> PoolProxiedConnection:\n\u001b[32m    440\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a DBAPI connection from the pool.\u001b[39;00m\n\u001b[32m    441\u001b[39m \n\u001b[32m    442\u001b[39m \u001b[33;03m    The connection is instrumented such that when its\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    445\u001b[39m \n\u001b[32m    446\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m447\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionFairy\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_checkout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:1264\u001b[39m, in \u001b[36m_ConnectionFairy._checkout\u001b[39m\u001b[34m(cls, pool, threadconns, fairy)\u001b[39m\n\u001b[32m   1256\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_checkout\u001b[39m(\n\u001b[32m   1258\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1261\u001b[39m     fairy: Optional[_ConnectionFairy] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1262\u001b[39m ) -> _ConnectionFairy:\n\u001b[32m   1263\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fairy:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m         fairy = \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1266\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m threadconns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1267\u001b[39m             threadconns.current = weakref.ref(fairy)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:711\u001b[39m, in \u001b[36m_ConnectionRecord.checkout\u001b[39m\u001b[34m(cls, pool)\u001b[39m\n\u001b[32m    709\u001b[39m     rec = cast(_ConnectionRecord, pool._do_get())\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m711\u001b[39m     rec = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_do_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    714\u001b[39m     dbapi_connection = rec.get_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\impl.py:177\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_connection()\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dec_overflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\util\\langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    226\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\impl.py:175\u001b[39m, in \u001b[36mQueuePool._do_get\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inc_overflow():\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    177\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m util.safe_reraise():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:388\u001b[39m, in \u001b[36mPool._create_connection\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ConnectionPoolEntry:\n\u001b[32m    386\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Called by subclasses to create a new ConnectionRecord.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m388\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ConnectionRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:673\u001b[39m, in \u001b[36m_ConnectionRecord.__init__\u001b[39m\u001b[34m(self, pool, connect)\u001b[39m\n\u001b[32m    671\u001b[39m \u001b[38;5;28mself\u001b[39m.__pool = pool\n\u001b[32m    672\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m connect:\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[38;5;28mself\u001b[39m.finalize_callback = deque()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:899\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    897\u001b[39m     \u001b[38;5;28mself\u001b[39m.fresh = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    898\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m899\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mError on connect(): \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    902\u001b[39m     \u001b[38;5;66;03m# in SQLAlchemy 1.4 the first_connect event is not used by\u001b[39;00m\n\u001b[32m    903\u001b[39m     \u001b[38;5;66;03m# the engine, so this will usually not be set\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\util\\langhelpers.py:224\u001b[39m, in \u001b[36msafe_reraise.__exit__\u001b[39m\u001b[34m(self, type_, value, traceback)\u001b[39m\n\u001b[32m    222\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value.with_traceback(exc_tb)\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    226\u001b[39m     \u001b[38;5;28mself\u001b[39m._exc_info = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\pool\\base.py:895\u001b[39m, in \u001b[36m_ConnectionRecord.__connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    894\u001b[39m     \u001b[38;5;28mself\u001b[39m.starttime = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m895\u001b[39m     \u001b[38;5;28mself\u001b[39m.dbapi_connection = connection = \u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_invoke_creator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    896\u001b[39m     pool.logger.debug(\u001b[33m\"\u001b[39m\u001b[33mCreated new connection \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, connection)\n\u001b[32m    897\u001b[39m     \u001b[38;5;28mself\u001b[39m.fresh = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\engine\\create.py:661\u001b[39m, in \u001b[36mcreate_engine.<locals>.connect\u001b[39m\u001b[34m(connection_record)\u001b[39m\n\u001b[32m    658\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    659\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m connection\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\sqlalchemy\\engine\\default.py:629\u001b[39m, in \u001b[36mDefaultDialect.connect\u001b[39m\u001b[34m(self, *cargs, **cparams)\u001b[39m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m, *cargs: Any, **cparams: Any) -> DBAPIConnection:\n\u001b[32m    628\u001b[39m     \u001b[38;5;66;03m# inherits the docstring from interfaces.Dialect.connect\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m629\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloaded_dbapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:365\u001b[39m, in \u001b[36mConnection.__init__\u001b[39m\u001b[34m(self, user, password, host, database, unix_socket, port, charset, collation, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_key_password, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001b[39m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:681\u001b[39m, in \u001b[36mConnection.connect\u001b[39m\u001b[34m(self, sock)\u001b[39m\n\u001b[32m    678\u001b[39m \u001b[38;5;28mself\u001b[39m._next_seq_id = \u001b[32m0\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28mself\u001b[39m._get_server_information()\n\u001b[32m--> \u001b[39m\u001b[32m681\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_authentication\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[38;5;66;03m# Send \"SET NAMES\" query on init for:\u001b[39;00m\n\u001b[32m    684\u001b[39m \u001b[38;5;66;03m# - Ensure charaset (and collation) is set to the server.\u001b[39;00m\n\u001b[32m    685\u001b[39m \u001b[38;5;66;03m#   - collation_id in handshake packet may be ignored.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    694\u001b[39m \u001b[38;5;66;03m# - https://github.com/wagtail/wagtail/issues/9477\u001b[39;00m\n\u001b[32m    695\u001b[39m \u001b[38;5;66;03m# - https://zenn.dev/methane/articles/2023-mysql-collation (Japanese)\u001b[39;00m\n\u001b[32m    696\u001b[39m \u001b[38;5;28mself\u001b[39m.set_character_set(\u001b[38;5;28mself\u001b[39m.charset, \u001b[38;5;28mself\u001b[39m.collation)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:980\u001b[39m, in \u001b[36mConnection._request_authentication\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    978\u001b[39m \u001b[38;5;66;03m# https://dev.mysql.com/doc/internals/en/successful-authentication.html\u001b[39;00m\n\u001b[32m    979\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._auth_plugin_name == \u001b[33m\"\u001b[39m\u001b[33mcaching_sha2_password\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     auth_packet = \u001b[43m_auth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaching_sha2_password_auth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_packet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._auth_plugin_name == \u001b[33m\"\u001b[39m\u001b[33msha256_password\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    982\u001b[39m     auth_packet = _auth.sha256_password_auth(\u001b[38;5;28mself\u001b[39m, auth_packet)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\_auth.py:272\u001b[39m, in \u001b[36mcaching_sha2_password_auth\u001b[39m\u001b[34m(conn, pkt)\u001b[39m\n\u001b[32m    269\u001b[39m         \u001b[38;5;28mprint\u001b[39m(conn.server_public_key.decode(\u001b[33m\"\u001b[39m\u001b[33mascii\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    271\u001b[39m data = sha2_rsa_encrypt(conn.password, conn.salt, conn.server_public_key)\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m pkt = \u001b[43m_roundtrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\_auth.py:121\u001b[39m, in \u001b[36m_roundtrip\u001b[39m\u001b[34m(conn, send_data)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_roundtrip\u001b[39m(conn, send_data):\n\u001b[32m    120\u001b[39m     conn.write_packet(send_data)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     pkt = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_read_packet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m     pkt.check_error()\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pkt\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\connections.py:782\u001b[39m, in \u001b[36mConnection._read_packet\u001b[39m\u001b[34m(self, packet_type)\u001b[39m\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.unbuffered_active \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    781\u001b[39m         \u001b[38;5;28mself\u001b[39m._result.unbuffered_active = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m     \u001b[43mpacket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m packet\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\protocol.py:219\u001b[39m, in \u001b[36mMysqlPacket.raise_for_error\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[32m    218\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33merrno =\u001b[39m\u001b[33m\"\u001b[39m, errno)\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m \u001b[43merr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_mysql_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pymysql\\err.py:150\u001b[39m, in \u001b[36mraise_mysql_exception\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m errorclass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    149\u001b[39m     errorclass = InternalError \u001b[38;5;28;01mif\u001b[39;00m errno < \u001b[32m1000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m OperationalError\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m errorclass(errno, errval)\n",
      "\u001b[31mOperationalError\u001b[39m: (pymysql.err.OperationalError) (1045, \"Access denied for user 'root'@'localhost' (using password: YES)\")\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "server_url = f\"mysql+pymysql://{MYSQL_USER}:{MYSQL_PWD}@{MYSQL_HOST}:{MYSQL_PORT}\"\n",
    "server_engine = create_engine(server_url, pool_pre_ping=True)\n",
    "\n",
    "with server_engine.connect() as conn:\n",
    "    conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS `{MYSQL_DB}` CHARACTER SET utf8mb4\"))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0ec96",
   "metadata": {},
   "source": [
    "3) Connect to the specific DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "576d31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_url = f\"{server_url}/{MYSQL_DB}?charset=utf8mb4\"\n",
    "engine = create_engine(db_url, pool_pre_ping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f5af8",
   "metadata": {},
   "source": [
    "4) Get data to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5bd0548",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_student_summary_df = ensure_df(\"fact_student_summary\", \"fact_student_summary.csv\")\n",
    "fact_cdc_age_df         = ensure_df(\"fact_cdc_age\", \"fact_cdc_age.csv\")\n",
    "fact_cdc_sex_df         = ensure_df(\"fact_cdc_sex\", \"fact_cdc_sex.csv\")\n",
    "\n",
    "# Enforce key dtypes to match schema (age INT, gender VARCHAR, indicator VARCHAR)\n",
    "fact_student_summary_df[\"age\"] = pd.to_numeric(fact_student_summary_df[\"age\"], errors=\"coerce\").astype(\"Int64\")\n",
    "fact_student_summary_df[\"gender\"] = fact_student_summary_df[\"gender\"].astype(str).str.title()\n",
    "fact_student_summary_df = fact_student_summary_df.dropna(subset=[\"age\",\"gender\"])\n",
    "\n",
    "fact_cdc_age_df[\"age\"] = pd.to_numeric(fact_cdc_age_df[\"age\"], errors=\"coerce\").astype(\"Int64\")\n",
    "fact_cdc_age_df = fact_cdc_age_df.dropna(subset=[\"indicator\",\"age\"])\n",
    "fact_cdc_age_df[\"indicator\"] = fact_cdc_age_df[\"indicator\"].astype(str)\n",
    "\n",
    "fact_cdc_sex_df[\"gender\"] = fact_cdc_sex_df[\"gender\"].astype(str).str.title()\n",
    "fact_cdc_sex_df[\"indicator\"] = fact_cdc_sex_df[\"indicator\"].astype(str)\n",
    "fact_cdc_sex_df = fact_cdc_sex_df.dropna(subset=[\"indicator\",\"gender\"])\n",
    "\n",
    "# Set MySQL dtypes for key columns\n",
    "from sqlalchemy.types import Integer, String\n",
    "\n",
    "fss_dtypes = {\"age\": Integer(), \"gender\": String(16)}\n",
    "cdc_age_dtypes = {\"indicator\": String(128), \"age\": Integer()}\n",
    "cdc_sex_dtypes = {\"indicator\": String(128), \"gender\": String(16)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d40280",
   "metadata": {},
   "source": [
    "5) Write to MySQL (overwrite for repeatable runs; change to 'append' if preferred)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a6c7801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading tables to MySQL...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Uploading tables to MySQL...\")\n",
    "fact_student_summary_df.to_sql(\n",
    "    \"fact_student_summary\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\", dtype=fss_dtypes\n",
    ")\n",
    "fact_cdc_age_df.to_sql(\n",
    "    \"fact_cdc_age\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\", dtype=cdc_age_dtypes\n",
    ")\n",
    "fact_cdc_sex_df.to_sql(\n",
    "    \"fact_cdc_sex\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\", dtype=cdc_sex_dtypes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d291d60",
   "metadata": {},
   "source": [
    "6) Quick verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b14d1870",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    for tbl in (\"fact_student_summary\", \"fact_cdc_age\", \"fact_cdc_sex\"):\n",
    "        n = conn.execute(text(f\"SELECT COUNT(*) FROM `{tbl}`\")).scalar()\n",
    "        print(f\"{tbl}: {n} rows\")\n",
    "\n",
    "print(\"Load complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1fe21f",
   "metadata": {},
   "source": [
    "### Dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ce1f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_dims = [\n",
    "    \"dim_age\",\"dim_gender\",\n",
    "]\n",
    "missing = [d for d in required_dims if d not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing dimension dataframes: {missing}. Run Transform first.\")\n",
    "\n",
    "# Deduplicate\n",
    "dim_age    = dim_age.drop_duplicates(subset=[\"age\"]).sort_values(\"age\")\n",
    "dim_gender = dim_gender.drop_duplicates(subset=[\"gender\"]).sort_values(\"gender\")\n",
    "\n",
    "# Write\n",
    "dim_age.to_sql(\"dim_age\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "dim_gender.to_sql(\"dim_gender\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "\n",
    "# Verify\n",
    "with engine.connect() as conn:\n",
    "    for tbl in (\"dim_age\",\"dim_gender\"):\n",
    "        n = conn.execute(text(f\"SELECT COUNT(*) FROM `{tbl}`\")).scalar()\n",
    "        print(f\"{tbl}: {n} rows\")\n",
    "\n",
    "print(\"Dimension load complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d6ba953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add primary/foreign keys after loads\n",
    "def run(sql):\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            conn.execute(text(sql))\n",
    "    except Exception as e:\n",
    "        print(\"Skip:\", e)\n",
    "\n",
    "# Dimension PKs\n",
    "run(\"ALTER TABLE dim_age MODIFY age INT NOT NULL;\")\n",
    "run(\"ALTER TABLE dim_age ADD PRIMARY KEY (age);\")\n",
    "\n",
    "run(\"ALTER TABLE dim_gender MODIFY gender VARCHAR(16) NOT NULL;\")\n",
    "run(\"ALTER TABLE dim_gender ADD PRIMARY KEY (gender);\")\n",
    "\n",
    "# Fact keys/FKs\n",
    "run(\"ALTER TABLE fact_student_summary MODIFY age INT NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_student_summary MODIFY gender VARCHAR(16) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_student_summary ADD PRIMARY KEY (age, gender);\")\n",
    "run(\"\"\"\n",
    "ALTER TABLE fact_student_summary\n",
    "  ADD CONSTRAINT fk_fss_age FOREIGN KEY (age) REFERENCES dim_age(age)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT,\n",
    "  ADD CONSTRAINT fk_fss_gender FOREIGN KEY (gender) REFERENCES dim_gender(gender)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT;\n",
    "\"\"\")\n",
    "\n",
    "run(\"ALTER TABLE fact_cdc_age MODIFY indicator VARCHAR(128) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_age MODIFY age INT NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_age ADD PRIMARY KEY (indicator, age);\")\n",
    "run(\"\"\"\n",
    "ALTER TABLE fact_cdc_age\n",
    "  ADD CONSTRAINT fk_cdc_age_age FOREIGN KEY (age) REFERENCES dim_age(age)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT;\n",
    "\"\"\")\n",
    "\n",
    "# fact_cdc_sex(indicator, gender)\n",
    "run(\"ALTER TABLE fact_cdc_sex MODIFY indicator VARCHAR(128) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_sex MODIFY gender VARCHAR(16) NOT NULL;\")\n",
    "run(\"ALTER TABLE fact_cdc_sex ADD PRIMARY KEY (indicator, gender);\")\n",
    "run(\"\"\"\n",
    "ALTER TABLE fact_cdc_sex\n",
    "  ADD CONSTRAINT fk_cdc_sex_gender FOREIGN KEY (gender) REFERENCES dim_gender(gender)\n",
    "    ON UPDATE CASCADE ON DELETE RESTRICT;\n",
    "\"\"\")\n",
    "\n",
    "print(\"Keys and constraints applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d44c2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = {\n",
    "    \"dim_age\": dim_age,\n",
    "    \"dim_gender\": dim_gender,\n",
    "}\n",
    "for name, df in dims.items():\n",
    "    df.to_csv(f\"{name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
