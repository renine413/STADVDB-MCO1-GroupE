{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b08927",
   "metadata": {},
   "source": [
    "# ETL Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a5dff2",
   "metadata": {},
   "source": [
    "## 1. Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456a45fc",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29bb4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b4124f",
   "metadata": {},
   "source": [
    "Read datasets\n",
    "1. Indicators of Anxiety or Depression Based on Reported Frequency of Symptoms During Last 7 Days\n",
    "2. Student Depression Dataset\n",
    "3. Student Mental Health Crisis After COVID-19\n",
    "4. Student Performance and Behavior Dataset\n",
    "5. Students Social Media Addiction Dataset\n",
    "6. PHQ-9 Student Depression Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6804be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json(\"datasets/cdc-indicators-of-anxiety-or-depression.json\")\n",
    "df2 = pd.read_csv(\"datasets/kaggle-student-depression-dataset.csv\")\n",
    "df3 = pd.read_excel(\"datasets/kaggle-student-mental-health-crisis-after-covid19-final.xlsx\")\n",
    "df4 = pd.read_json(\"datasets/kaggle-student-performance-and-behavior-dataset.json\")\n",
    "df5 = pd.read_csv(\"datasets/kaggle-students-social-media-addiction.csv\")\n",
    "df6 = pd.read_csv(\"datasets/mendeley-phq9-student-depression-dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaed702",
   "metadata": {},
   "source": [
    "## 2. Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3946b",
   "metadata": {},
   "source": [
    "### Data Preprocessing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b1ad28",
   "metadata": {},
   "source": [
    "1. Rename columns for clarity and consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c409f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = [\"indicator\", \"grp\", \"state\", \"subgroup\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"value\", \"low_CI\", \"high_CI\", \"confidence_interval\", \"quartile_range\"]\n",
    "df2.columns = [\"id\", \"gender\", \"age\", \"city\", \"profession\", \"academic_pressure\", \"work_pressure\", \"cgpa\", \"study_satisfaction\", \"job_satisfaction\", \"sleep_duration\", \"dietary_habits\", \"degree\", \"has_suicidal_thoughts\", \"work_study_hours\", \"financial_stress\", \"has_family_mental_illness\", \"has_depression\"]\n",
    "df3.columns = [\"gender\", \"age\", \"city\", \"profession\", \"academic_pressure\", \"work_pressure\", \"cgpa\", \"study_satisfaction\", \"job_satisfaction\", \"sleep_duration\", \"dietary_habits\", \"degree\", \"has_suicidal_thoughts\", \"work_study_hours\", \"financial_stress\", \"has_family_mental_illness\", \"has_depression\"]\n",
    "df4.columns = [\"student_id\", \"first_name\", \"last_name\", \"email\", \"gender\", \"age\", \"department\", \"attendance\", \"midterm_score\", \"final_score\", \"assignments_ave\", \"quizzes_ave\", \"participation_score\", \"projects_score\", \"total_score\", \"grade\", \"study_hours_per_week\", \"has_extracurricular\", \"has_internet_access\", \"parent_education_level\", \"family_income_level\", \"stress_level\", \"sleep_hours\"]\n",
    "df5.columns = [\"student_id\", \"age\", \"gender\", \"academic_level\", \"country\", \"ave_daily_usage_hours\", \"most_used_platform\", \"affects_academic_performance\", \"sleep_hours\", \"mental_health_score\", \"relationship_status\", \"conflicts_over_social_media\", \"addicted_score\"] \n",
    "df6.columns = ['age','gender','interest_loss','depressed_mood','sleep_trouble','fatigue','appetite_change','guilt_failure','concentration','fidgety_restless','suicidal_thoughts','phq9_score','depression_level']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf97498",
   "metadata": {},
   "source": [
    "2. Split DF1 into two dataframes based on gender and age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "855f4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1[\"grp\"].isin([\"By Age\", \"By Sex\"])]\n",
    "df1_age = df1[df1[\"grp\"] == \"By Age\"].copy()\n",
    "df1_sex = df1[df1[\"grp\"] == \"By Sex\"].copy()\n",
    "df1_age = df1_age.rename(columns={\"subgroup\": \"age\"})\n",
    "df1_sex = df1_sex.rename(columns={\"subgroup\": \"gender\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f7ee9f",
   "metadata": {},
   "source": [
    "3. Drop unnecessary columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e89e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age = df1_age.drop(columns=[\"grp\", \"state\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"quartile_range\"])\n",
    "df1_sex = df1_sex.drop(columns=[\"grp\", \"state\", \"phase\", \"time_period\", \"time_period_label\", \"time_period_start_date\", \"time_period_end_date\", \"quartile_range\"])\n",
    "df2 = df2.drop(columns=[\"id\", \"city\", \"profession\", \"work_pressure\", \"job_satisfaction\"])\n",
    "df3 = df3.drop(columns=[\"city\", \"profession\", \"work_pressure\", \"job_satisfaction\"])\n",
    "df4 = df4.drop(columns=[\"student_id\", \"first_name\", \"last_name\", \"email\", \"grade\"])\n",
    "df5 = df5.drop(columns=[\"student_id\", \"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5e6f6",
   "metadata": {},
   "source": [
    "4. Drop rows with exceeding age groups and missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742a5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age = df1_age[~df1_age[\"age\"].isin(['60 - 69 years', '70 - 79 years', '80 years and above'])]\n",
    "df4 = df4.dropna(subset=[\"attendance\", \"assignments_ave\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9264786d",
   "metadata": {},
   "source": [
    "5. Fill missing values with mean and default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fbf47cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"financial_stress\"] = df2[\"financial_stress\"].fillna(df2[\"financial_stress\"].mean())\n",
    "df4[\"parent_education_level\"] = df4[\"parent_education_level\"].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459c874",
   "metadata": {},
   "source": [
    "### Data Type Normalization and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248a3dc",
   "metadata": {},
   "source": [
    "1. Convert age from float to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "047e9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"age\"] = df2[\"age\"].fillna(df2[\"age\"].median()).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6986f",
   "metadata": {},
   "source": [
    "2. Convert confidence interval values to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91a96111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_age['value'] = pd.to_numeric(df1_age['value'], errors='coerce')\n",
    "df1_age['low_CI'] = pd.to_numeric(df1_age['low_CI'], errors='coerce')\n",
    "df1_age['high_CI'] = pd.to_numeric(df1_age['high_CI'], errors='coerce')\n",
    "\n",
    "df1_sex['value'] = pd.to_numeric(df1_sex['value'], errors='coerce')\n",
    "df1_sex['low_CI'] = pd.to_numeric(df1_sex['low_CI'], errors='coerce')\n",
    "df1_sex['high_CI'] = pd.to_numeric(df1_sex['high_CI'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0304bc",
   "metadata": {},
   "source": [
    "3. Convert boolean columns from 'Yes'/'No' to 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dad8040",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_columns = {\n",
    "    'df2': [\"has_suicidal_thoughts\", \"has_family_mental_illness\"],\n",
    "    'df3': [\"has_suicidal_thoughts\", \"has_family_mental_illness\", \"has_depression\"],\n",
    "    'df4': [\"has_extracurricular\", \"has_internet_access\"],\n",
    "    'df5': [\"affects_academic_performance\"],\n",
    "}\n",
    "\n",
    "for df_name, columns in bool_columns.items():\n",
    "    df = globals()[df_name]\n",
    "    for col in columns:\n",
    "        df[col] = df[col].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c50a8",
   "metadata": {},
   "source": [
    "4. Map sleep hours to average values in DF2 and DF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "015a9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_map = {\n",
    "    'Less than 5 hours': 4.5,\n",
    "    '5-6 hours': 5.5,\n",
    "    '7-8 hours': 7.5,\n",
    "    'More than 8 hours': 9,\n",
    "    'Others': None\n",
    "}\n",
    "df2['sleep_duration'] = df2['sleep_duration'].map(sleep_map)\n",
    "df3['sleep_duration'] = df3['sleep_duration'].map(sleep_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7871e570",
   "metadata": {},
   "source": [
    "5. Map survery response and depresssion levels to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1d61b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_cols = [\n",
    "    'interest_loss',\n",
    "    'depressed_mood',\n",
    "    'sleep_trouble',\n",
    "    'fatigue',\n",
    "    'appetite_change',\n",
    "    'guilt_failure',\n",
    "    'concentration',\n",
    "    'fidgety_restless',\n",
    "    'suicidal_thoughts'\n",
    "]\n",
    "\n",
    "depression_mapping = {\n",
    "    'Minimal': 0,\n",
    "    'Mild': 1,\n",
    "    'Moderate': 2,\n",
    "    'Moderately Severe': 3,\n",
    "    'Severe': 4\n",
    "}\n",
    "\n",
    "mapping = {\n",
    "    'Not at all': 0,\n",
    "    'Several days': 1,\n",
    "    'More than half the days': 2,\n",
    "    'Nearly every day': 3\n",
    "}\n",
    "\n",
    "df6[survey_cols] = df6[survey_cols].apply(lambda col: col.map(mapping))\n",
    "df6['depression_level'] = df6['depression_level'].map(depression_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "963a1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode academic_level in DF5\n",
    "df5['academic_level'] = df5['academic_level'].astype(str).str.strip()\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['academic_level'], prefix='academic_level')], axis=1)\n",
    "df5.drop(columns=['academic_level'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "025f68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode dietary_habits in DF2 and DF3\n",
    "df2 = pd.concat([df2, pd.get_dummies(df2['dietary_habits'], prefix='diet')], axis=1)\n",
    "df3 = pd.concat([df3, pd.get_dummies(df3['dietary_habits'], prefix='diet')], axis=1)\n",
    "df2.drop(columns=['dietary_habits'], inplace=True)\n",
    "df3.drop(columns=['dietary_habits'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3803b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode most_used_platform and relationship_status in DF5\n",
    "df5['relationship_status'] = df5['relationship_status'].str.strip().str.lower().str.replace(' ', '_')\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['most_used_platform'], prefix='most_used')], axis=1)\n",
    "df5 = pd.concat([df5, pd.get_dummies(df5['relationship_status'], prefix='rel_status')], axis=1)\n",
    "df5.drop(columns=['most_used_platform', 'relationship_status'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea4b0a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender', 'age', 'academic_pressure', 'cgpa', 'study_satisfaction', 'sleep_duration', 'degree', 'has_suicidal_thoughts', 'work_study_hours', 'financial_stress', 'has_family_mental_illness', 'has_depression', 'diet_Healthy', 'diet_Moderate', 'diet_Unhealthy']\n"
     ]
    }
   ],
   "source": [
    "print(df3.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f31af",
   "metadata": {},
   "source": [
    "### Aggregate to Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "343b6b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact student summary shape: (16, 71)\n",
      "  age_group  gender  avg_academic_pressure  avg_cgpa  avg_study_satisfaction  \\\n",
      "0     18-24  Female               3.232624  7.599771                2.951567   \n",
      "1     18-24    Male               3.172835  7.693416                2.874469   \n",
      "2     25-29  Female               3.248344  7.608493                2.972105   \n",
      "3     25-29    Male               3.189327  7.732525                2.919923   \n",
      "4     30-34  Female               3.016140  7.589987                2.982016   \n",
      "\n",
      "   avg_sleep_duration  avg_has_suicidal_thoughts  avg_work_study_hours  \\\n",
      "0            6.501964                   0.686032              7.168854   \n",
      "1            6.509951                   0.677160              7.341582   \n",
      "2            6.456784                   0.632539              7.128029   \n",
      "3            6.457953                   0.651475              7.164055   \n",
      "4            6.483006                   0.553677              6.917934   \n",
      "\n",
      "   avg_financial_stress  avg_has_family_mental_illness  ...  \\\n",
      "0              3.313071                       0.500691  ...   \n",
      "1              3.272125                       0.477489  ...   \n",
      "2              3.095794                       0.477811  ...   \n",
      "3              3.131898                       0.482400  ...   \n",
      "4              2.951264                       0.497713  ...   \n",
      "\n",
      "   most_used_snapchat  most_used_tiktok  most_used_twitter  \\\n",
      "0            0.000000          0.250737           0.000000   \n",
      "1            0.120243          0.210369           0.066611   \n",
      "2            0.000000          0.000000           0.000000   \n",
      "3            0.000000          0.000000           0.000000   \n",
      "4            0.000000          0.000000           0.000000   \n",
      "\n",
      "   most_used_vkontakte  most_used_wechat  most_used_whatsapp  \\\n",
      "0                  0.0          0.250969                 0.0   \n",
      "1                  0.0          0.000000                 0.0   \n",
      "2                  0.0          0.000000                 0.0   \n",
      "3                  0.0          0.000000                 0.0   \n",
      "4                  0.0          0.000000                 0.0   \n",
      "\n",
      "   most_used_youtube  rel_status_complicated  rel_status_in_relationship  \\\n",
      "0           0.000000                0.250737                    0.649462   \n",
      "1           0.109847                0.330612                    0.150480   \n",
      "2           0.000000                0.000000                    0.000000   \n",
      "3           0.000000                0.000000                    0.000000   \n",
      "4           0.000000                0.000000                    0.000000   \n",
      "\n",
      "   rel_status_single  \n",
      "0           0.099801  \n",
      "1           0.518908  \n",
      "2           0.000000  \n",
      "3           0.000000  \n",
      "4           0.000000  \n",
      "\n",
      "[5 rows x 71 columns]\n",
      "Fact CDC age shape: (24, 5)\n",
      "Fact CDC sex shape: (6, 5)\n",
      "Dimension tables sizes: age_group: 8 gender: 2 degree: 28 department: 4 platforms: 12 relationships: 3\n",
      "Dimension tables sizes: age_group: 8 gender: 2 degree: 28 department: 4 platforms: 12 relationships: 3 academic_levels: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fonte\\AppData\\Local\\Temp\\ipykernel_11572\\3591008763.py:177: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  numeric_summary = base.groupby(group_cols, as_index=False)[numeric_non_onehot].mean()\n",
      "C:\\Users\\fonte\\AppData\\Local\\Temp\\ipykernel_11572\\3591008763.py:181: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  onehot_summary = base.groupby(group_cols, as_index=False)[one_hot_cols].mean()\n"
     ]
    }
   ],
   "source": [
    "# ---------- 0. SETTINGS ----------\n",
    "# age bins used throughout (you chose 18-60 range)\n",
    "bins = [18, 25, 30, 35, 40, 45, 50, 55, 60]\n",
    "labels = ['18-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59']\n",
    "\n",
    "# helper to normalize column names\n",
    "def normalize_cols(df):\n",
    "    df = df.copy()\n",
    "    df.columns = (\n",
    "        df.columns\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(' ', '_', regex=False)\n",
    "        .str.replace(r'[^0-9a-zA-Z_]', '', regex=True)  # remove weird chars\n",
    "        .str.replace('__', '_', regex=False)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# ---------- 1. Normalize column names for all dataframes ----------\n",
    "df1_age = normalize_cols(df1_age)\n",
    "df1_sex = normalize_cols(df1_sex)\n",
    "df2 = normalize_cols(df2)\n",
    "df3 = normalize_cols(df3)\n",
    "df4 = normalize_cols(df4)\n",
    "df5 = normalize_cols(df5)\n",
    "df6 = normalize_cols(df6)\n",
    "\n",
    "# ---------- 2. Create age_group for individual-level datasets (df2..df6) ----------\n",
    "for df in (df2, df3, df4, df5, df6):\n",
    "    # Ensure age is numeric\n",
    "    df['age'] = pd.to_numeric(df['age'], errors='coerce')\n",
    "    # Keep only 18-59 (as you requested); rows outside become NaN for age_group\n",
    "    df['age_group'] = pd.cut(df['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# ---------- 3. Clean and convert CDC (df1_age, df1_sex) numeric columns ----------\n",
    "for df in (df1_age, df1_sex):\n",
    "    for col in ['value','low_ci','high_ci']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# OPTIONAL: drop CDC rows outside 18-59 for df1_age (based on textual ranges)\n",
    "# We will split ranges like '18 - 29 years' into two subgroups (18-24,25-29)\n",
    "split_mapping = {\n",
    "    '18 - 29 years': ['18-24','25-29'],\n",
    "    '30 - 39 years': ['30-34','35-39'],\n",
    "    '40 - 49 years': ['40-44','45-49'],\n",
    "    '50 - 59 years': ['50-54','55-59']\n",
    "}\n",
    "\n",
    "# Make a copy and safely explode df1_age into finer groups\n",
    "def expand_cdc_age(df_age):\n",
    "    df = df_age.copy()\n",
    "    # Ensure the \"age\" column contains the textual subgroup (if named differently adjust)\n",
    "    # We'll create a new column 'age_group' as list using mapping, then explode\n",
    "    df['target_age_groups'] = df['age'].map(lambda s: split_mapping.get(str(s).strip(), None))\n",
    "    # Keep only rows that map to our allowed ranges\n",
    "    df = df[df['target_age_groups'].notna()].copy()\n",
    "    # explode\n",
    "    df = df.explode('target_age_groups').rename(columns={'target_age_groups':'age_group'})\n",
    "    # evenly distribute value and CIs across parts (i.e., divide by number of parts per original)\n",
    "    # To do this, compute counts per original index:\n",
    "    counts = df.groupby(df.index).size()\n",
    "    counts = counts.rename('n_parts')\n",
    "    df = df.join(counts, how='left')\n",
    "    for col in ['value','low_ci','high_ci']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col] / df['n_parts']\n",
    "    df.drop(columns=['n_parts'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# Apply expansion (if df1_age uses textual ranges as you showed)\n",
    "try:\n",
    "    cdc_age_expanded = expand_cdc_age(df1_age)\n",
    "except Exception:\n",
    "    # if mapping fails for any reason, fall back to filtering and mapping directly if exact matches exist\n",
    "    cdc_age_expanded = df1_age.copy()\n",
    "    cdc_age_expanded['age_group'] = cdc_age_expanded['age'].map({\n",
    "        '18 - 29 years':'18-24', '30 - 39 years':'30-39', '40 - 49 years':'40-49', '50 - 59 years':'50-59'\n",
    "    })\n",
    "\n",
    "# For df1_sex ensure gender names are normalized\n",
    "df1_sex['gender'] = (df1_sex['gender'].astype(str)\n",
    "                     .str.strip().str.lower().replace({'male':'male','female':'female'}))\n",
    "# canonicalize to capitalized or lower consistently; we'll use title case in final dims\n",
    "df1_sex['gender'] = df1_sex['gender'].str.title()\n",
    "\n",
    "# ---------- 4. Prepare one-hot column lists (after normalization these are predictable) ----------\n",
    "onehot_prefixes = ('diet_', 'most_used_', 'rel_status_', 'academic_level_')\n",
    "one_hot_cols = [col for col in pd.concat([df2, df3, df5], ignore_index=True).columns\n",
    "                if col.startswith(onehot_prefixes)]\n",
    "\n",
    "# Remove duplicates and ensure existence in combined fact_student later\n",
    "one_hot_cols = sorted(set(one_hot_cols))\n",
    "\n",
    "# ---------- 5. Build combined student table but avoid creating monstrous intermediate objects ----------\n",
    "# We'll not concat all rows wide first; instead we'll merge carefully and then select columns we will aggregate.\n",
    "\n",
    "# Normalize merge keys\n",
    "for df in (df2, df3, df4, df5, df6):\n",
    "    df['gender'] = df['gender'].astype(str).str.strip().str.title()\n",
    "\n",
    "# Start with df2 as base (individual-level)\n",
    "base = df2.copy()\n",
    "\n",
    "# When merging df3, drop columns that are duplicates in base to avoid wide duplication\n",
    "cols_to_drop_from_df3 = [c for c in ['degree','sleep_duration','diet_healthy','diet_moderate','diet_unhealthy'] if c in df3.columns]\n",
    "df3_for_merge = df3.drop(columns=cols_to_drop_from_df3)\n",
    "\n",
    "# Merge step-by-step; keep only needed columns to reduce memory\n",
    "base = base.merge(df3_for_merge, on=['age','gender'], how='left', suffixes=('','_df3'))\n",
    "\n",
    "# Merge df4: keep numeric/performance columns + department/parent_education_level/family_income_level\n",
    "df4_keep = [c for c in ['attendance','midterm_score','final_score','assignments_ave','quizzes_ave',\n",
    "                        'participation_score','projects_score','total_score','study_hours_per_week',\n",
    "                        'has_extracurricular','has_internet_access','parent_education_level',\n",
    "                        'family_income_level','department','stress_level','sleep_hours'] if c in df4.columns]\n",
    "base = base.merge(df4[df4_keep + ['age','gender']].drop_duplicates(subset=['age','gender']), on=['age','gender'], how='left')\n",
    "\n",
    "# Merge df5: keep numeric + one-hot platform + rel_status + academic_level\n",
    "df5_keep = [c for c in df5.columns if c in ['ave_daily_usage_hours','affects_academic_performance',\n",
    "                                            'sleep_hours','mental_health_score','conflicts_over_social_media','addicted_score',\n",
    "                                            'age','gender']]\n",
    "# also include any one-hot platform, relationship, and academic_level columns\n",
    "df5_onehots = [c for c in df5.columns if c.startswith('most_used_') or c.startswith('rel_status_') or c.startswith('academic_level_')]\n",
    "df5_keep = list(dict.fromkeys(df5_keep + df5_onehots))  # preserve order\n",
    "base = base.merge(\n",
    "    df5[df5_keep].drop_duplicates(subset=['age','gender']),\n",
    "    on=['age','gender'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge df6: survey and phq9 score\n",
    "df6_keep = [c for c in ['interest_loss','depressed_mood','sleep_trouble','fatigue','appetite_change',\n",
    "                        'guilt_failure','concentration','fidgety_restless','suicidal_thoughts','phq9_score','depression_level','age','gender'] if c in df6.columns]\n",
    "base = base.merge(df6[df6_keep].drop_duplicates(subset=['age','gender']), on=['age','gender'], how='left')\n",
    "\n",
    "# Now 'base' is a reasonably-wide per-student table but not exploded by duplicated columns.\n",
    "\n",
    "# ---------- 6. Identify numeric and one-hot columns for aggregation ----------\n",
    "# Numeric columns: numbers and bools (coerce non-numeric to NaN)\n",
    "numeric_candidates = base.select_dtypes(include=['number','bool']).columns.tolist()\n",
    "\n",
    "# Some numeric-like columns may still be object due to NaNs; coerce those we expect to be numeric\n",
    "to_float_try = ['cgpa','academic_pressure','study_satisfaction','work_study_hours','financial_stress',\n",
    "                'attendance','midterm_score','final_score','assignments_ave','quizzes_ave','participation_score',\n",
    "                'projects_score','total_score','study_hours_per_week','stress_level','sleep_hours',\n",
    "                'ave_daily_usage_hours','mental_health_score','conflicts_over_social_media','addicted_score',\n",
    "                'phq9_score']\n",
    "for c in to_float_try:\n",
    "    if c in base.columns:\n",
    "        base[c] = pd.to_numeric(base[c], errors='coerce')\n",
    "\n",
    "# Now recompute numeric columns\n",
    "numeric_cols = [c for c in base.select_dtypes(include=['number','bool','float','int']).columns if c not in ['age']]\n",
    "\n",
    "# Exclude one-hot cols from numeric_cols (we will aggregate them separately)\n",
    "one_hot_cols = [c for c in base.columns if (\n",
    "    c.startswith('diet_') or c.startswith('most_used_') or c.startswith('rel_status_') or c.startswith('academic_level_')\n",
    ")]\n",
    "numeric_non_onehot = [c for c in numeric_cols if c not in one_hot_cols]\n",
    "\n",
    "# Convert numeric_non_onehot to float32 to save memory\n",
    "for c in numeric_non_onehot:\n",
    "    try:\n",
    "        base[c] = base[c].astype('float32')\n",
    "    except Exception:\n",
    "        base[c] = pd.to_numeric(base[c], errors='coerce').astype('float32')\n",
    "\n",
    "# Convert one-hot columns to float32 as well (they are 0/1)\n",
    "for c in one_hot_cols:\n",
    "    base[c] = pd.to_numeric(base[c], errors='coerce').fillna(0).astype('float32')\n",
    "\n",
    "# ---------- 7. Aggregate (memory-safe) ----------\n",
    "group_cols = ['age_group','gender']\n",
    "\n",
    "# (A) Numeric non-onehot aggregation\n",
    "numeric_summary = base.groupby(group_cols, as_index=False)[numeric_non_onehot].mean()\n",
    "\n",
    "# (B) One-hot aggregation\n",
    "if one_hot_cols:\n",
    "    onehot_summary = base.groupby(group_cols, as_index=False)[one_hot_cols].mean()\n",
    "    # Merge numeric + onehot summaries\n",
    "    fact_student_summary = pd.merge(numeric_summary, onehot_summary, on=group_cols, how='outer')\n",
    "else:\n",
    "    fact_student_summary = numeric_summary\n",
    "\n",
    "# ---------- 8. Postprocess fact_student_summary ----------\n",
    "# Optionally rename aggregates to make it clear they are group-level means\n",
    "# e.g., add prefix 'avg_' to numeric_non_onehot columns\n",
    "rename_map = {c: ('avg_' + c) for c in numeric_non_onehot}\n",
    "fact_student_summary.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# one-hot columns already represent fractions/proportions (0..1)\n",
    "# reset index order\n",
    "fact_student_summary = fact_student_summary.sort_values(['age_group','gender']).reset_index(drop=True)\n",
    "\n",
    "print(\"Fact student summary shape:\", fact_student_summary.shape)\n",
    "print(fact_student_summary.head())\n",
    "\n",
    "# ---------- 9. Build CDC fact tables (age and sex) ----------\n",
    "# df1_age expanded -> cdc_age_expanded already built above\n",
    "# aggregate by indicator, age_group\n",
    "fact_cdc_age = (cdc_age_expanded\n",
    "                .groupby(['indicator','age_group'], as_index=False)\n",
    "                .agg({'value':'mean','low_ci':'mean','high_ci':'mean'}))\n",
    "\n",
    "# df1_sex: normalize gender, aggregate by indicator, gender\n",
    "df1_sex['gender'] = df1_sex['gender'].str.title()\n",
    "fact_cdc_sex = (df1_sex\n",
    "                .groupby(['indicator','gender'], as_index=False)\n",
    "                .agg({'value':'mean','low_ci':'mean','high_ci':'mean'}))\n",
    "\n",
    "print(\"Fact CDC age shape:\", fact_cdc_age.shape)\n",
    "print(\"Fact CDC sex shape:\", fact_cdc_sex.shape)\n",
    "\n",
    "# ---------- 10. Build simple dimension tables ----------\n",
    "dim_age_group = pd.DataFrame({'age_group': labels, 'age_group_order': range(len(labels))})\n",
    "dim_gender = pd.DataFrame({'gender': sorted(fact_student_summary['gender'].dropna().unique())})\n",
    "\n",
    "# degree dimension (from df2+df3)\n",
    "degree_vals = pd.Series(pd.concat([df2['degree'], df3['degree']]).dropna().unique())\n",
    "dim_degree = pd.DataFrame({'degree': degree_vals}).reset_index().rename(columns={'index':'degree_id'})\n",
    "\n",
    "# department and family_income from df4 if available\n",
    "dim_department = pd.DataFrame({'department': df4['department'].dropna().unique()}).reset_index().rename(columns={'index':'department_id'})\n",
    "dim_family_income = pd.DataFrame({'family_income_level': df4['family_income_level'].dropna().unique()}).reset_index().rename(columns={'index':'income_id'})\n",
    "\n",
    "# social platform and relationship dims\n",
    "platform_cols = [c for c in base.columns if c.startswith('most_used_')]\n",
    "platform_names = [c.replace('most_used_','') for c in platform_cols]\n",
    "dim_platform = pd.DataFrame({'platform_col': platform_cols, 'platform': platform_names})\n",
    "\n",
    "relationship_cols = [c for c in base.columns if c.startswith('rel_status_')]\n",
    "relationship_names = [c.replace('rel_status_','') for c in relationship_cols]\n",
    "dim_relationship = pd.DataFrame({'rel_col': relationship_cols, 'relationship': relationship_names})\n",
    "\n",
    "print(\"Dimension tables sizes: age_group:\", len(dim_age_group), \"gender:\", len(dim_gender),\n",
    "    \"degree:\", len(dim_degree), \"department:\", len(dim_department),\n",
    "    \"platforms:\", len(dim_platform), \"relationships:\", len(dim_relationship))\n",
    "\n",
    "academic_cols = [c for c in base.columns if c.startswith('academic_level_')]\n",
    "academic_names = [c.replace('academic_level_','') for c in academic_cols]\n",
    "dim_academic_level = pd.DataFrame({'academic_col': academic_cols, 'academic_level': academic_names})\n",
    "\n",
    "print(\"Dimension tables sizes: age_group:\", len(dim_age_group), \"gender:\", len(dim_gender),\n",
    "    \"degree:\", len(dim_degree), \"department:\", len(dim_department),\n",
    "    \"platforms:\", len(dim_platform), \"relationships:\", len(dim_relationship),\n",
    "    \"academic_levels:\", len(dim_academic_level))\n",
    "\n",
    "# ---------- 11. Final: show outputs ----------\n",
    "# fact_student_summary (one row per age_group x gender) is your main fact table for visualizations\n",
    "# fact_cdc_age, fact_cdc_sex are CDC facts for reference\n",
    "# dims: dim_age_group, dim_gender, dim_degree, dim_department, dim_family_income, dim_platform, dim_relationship\n",
    "\n",
    "fact_student_summary.to_csv(\"fact_student_summary.csv\", index=False)\n",
    "fact_cdc_age.to_csv(\"fact_cdc_age.csv\", index=False)\n",
    "fact_cdc_sex.to_csv(\"fact_cdc_sex.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b271106",
   "metadata": {},
   "source": [
    "## 3. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0712ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'admin'\n",
    "password = 'root'\n",
    "host = 'localhost'          \n",
    "port = '3306'               \n",
    "database = 'olap_dashboard'  \n",
    "\n",
    "engine = create_engine(\"mysql+mysqlconnector://root:admin@localhost:3306/olap_dashboard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b14d1870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading tables to MySQL...\n",
      "fact_student_summary: 16 rows\n",
      "fact_cdc_age: 24 rows\n",
      "fact_cdc_sex: 6 rows\n",
      "Load complete.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# 1) Read connection settings\n",
    "MYSQL_HOST = os.getenv(\"MYSQL_HOST\", \"localhost\")\n",
    "MYSQL_PORT = int(os.getenv(\"MYSQL_PORT\", \"3306\"))\n",
    "MYSQL_DB   = os.getenv(\"MYSQL_DB\", \"olap_dashboard\")\n",
    "MYSQL_USER = os.getenv(\"MYSQL_USER\", \"root\")\n",
    "MYSQL_PWD  = os.getenv(\"MYSQL_PASSWORD\", \"admin\")\n",
    "\n",
    "if not MYSQL_PWD:\n",
    "    raise RuntimeError(\"Missing MYSQL_PASSWORD. Put it in .env or export it in your terminal.\")\n",
    "\n",
    "# 2) Ensure database exists (connect to server without DB first)\n",
    "server_url = f\"mysql+pymysql://{MYSQL_USER}:{MYSQL_PWD}@{MYSQL_HOST}:{MYSQL_PORT}\"\n",
    "server_engine = create_engine(server_url, pool_pre_ping=True)\n",
    "\n",
    "with server_engine.connect() as conn:\n",
    "    conn.execute(text(f\"CREATE DATABASE IF NOT EXISTS `{MYSQL_DB}` CHARACTER SET utf8mb4\"))\n",
    "    conn.commit()\n",
    "\n",
    "# 3) Connect to the specific DB\n",
    "db_url = f\"{server_url}/{MYSQL_DB}?charset=utf8mb4\"\n",
    "engine = create_engine(db_url, pool_pre_ping=True)\n",
    "\n",
    "# Helper: use in-memory DF if available, else load the CSV from disk\n",
    "def ensure_df(var_name: str, csv_path: str) -> pd.DataFrame:\n",
    "    if var_name in globals() and isinstance(globals()[var_name], pd.DataFrame):\n",
    "        return globals()[var_name]\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "# 4) Get data to load\n",
    "fact_student_summary_df = ensure_df(\"fact_student_summary\", \"fact_student_summary.csv\")\n",
    "fact_cdc_age_df         = ensure_df(\"fact_cdc_age\", \"fact_cdc_age.csv\")\n",
    "fact_cdc_sex_df         = ensure_df(\"fact_cdc_sex\", \"fact_cdc_sex.csv\")\n",
    "\n",
    "# 5) Write to MySQL (overwrite for repeatable runs; change to 'append' if preferred)\n",
    "print(\"Uploading tables to MySQL...\")\n",
    "fact_student_summary_df.to_sql(\n",
    "    \"fact_student_summary\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\"\n",
    ")\n",
    "fact_cdc_age_df.to_sql(\n",
    "    \"fact_cdc_age\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\"\n",
    ")\n",
    "fact_cdc_sex_df.to_sql(\n",
    "    \"fact_cdc_sex\", engine, if_exists=\"replace\", index=False, chunksize=1000, method=\"multi\"\n",
    ")\n",
    "\n",
    "# 6) Quick verification\n",
    "with engine.connect() as conn:\n",
    "    for tbl in (\"fact_student_summary\", \"fact_cdc_age\", \"fact_cdc_sex\"):\n",
    "        n = conn.execute(text(f\"SELECT COUNT(*) FROM `{tbl}`\")).scalar()\n",
    "        print(f\"{tbl}: {n} rows\")\n",
    "\n",
    "print(\"Load complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ce1f176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading dimension tables to MySQL...\n",
      "dim_age_group: 8 rows\n",
      "dim_gender: 2 rows\n",
      "dim_degree: 28 rows\n",
      "dim_department: 4 rows\n",
      "dim_family_income: 3 rows\n",
      "dim_platform: 12 rows\n",
      "dim_relationship: 3 rows\n",
      "dim_academic_level: 3 rows\n",
      "Dimension load complete.\n"
     ]
    }
   ],
   "source": [
    "# 3. Load — dimensions\n",
    "\n",
    "# Reuse the same 'engine' from the previous Load cell\n",
    "try:\n",
    "    engine\n",
    "except NameError:\n",
    "    raise RuntimeError(\"MySQL engine is not defined. Run the previous Load cell first.\")\n",
    "\n",
    "# Ensure the dim DataFrames exist (they're created in the Transform section)\n",
    "required_dims = [\n",
    "    \"dim_age_group\",\"dim_gender\",\"dim_degree\",\n",
    "    \"dim_department\",\"dim_family_income\",\"dim_platform\",\"dim_relationship\",\n",
    "    \"dim_academic_level\",\n",
    "]\n",
    "missing = [d for d in required_dims if d not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing dimension dataframes: {missing}. Run the Transform section first: {missing}\")\n",
    "\n",
    "# De-duplicate for clean loads\n",
    "dim_age_group     = dim_age_group.drop_duplicates(subset=[\"age_group\"]).sort_values(\"age_group\")\n",
    "dim_gender        = dim_gender.drop_duplicates(subset=[\"gender\"]).sort_values(\"gender\")\n",
    "dim_degree        = dim_degree.drop_duplicates(subset=[\"degree\"]).sort_values(\"degree\")\n",
    "dim_department    = dim_department.drop_duplicates(subset=[\"department\"]).sort_values(\"department\")\n",
    "dim_family_income = dim_family_income.drop_duplicates(subset=[\"family_income_level\"]).sort_values(\"family_income_level\")\n",
    "dim_platform      = dim_platform.drop_duplicates(subset=[\"platform_col\",\"platform\"]).sort_values(\"platform\")\n",
    "dim_relationship  = dim_relationship.drop_duplicates(subset=[\"rel_col\",\"relationship\"]).sort_values(\"relationship\")\n",
    "dim_academic_level = dim_academic_level.drop_duplicates(subset=[\"academic_col\",\"academic_level\"]).sort_values(\"academic_level\")\n",
    "\n",
    "print(\"Uploading dimension tables to MySQL...\")\n",
    "\n",
    "dim_age_group.to_sql(\"dim_age_group\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "dim_gender.to_sql(\"dim_gender\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "dim_degree.to_sql(\"dim_degree\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "dim_department.to_sql(\"dim_department\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "dim_family_income.to_sql(\"dim_family_income\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "dim_platform.to_sql(\"dim_platform\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "dim_relationship.to_sql(\"dim_relationship\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "dim_academic_level.to_sql(\"dim_academic_level\", engine, if_exists=\"replace\", index=False, method=\"multi\")\n",
    "\n",
    "# Verify\n",
    "with engine.connect() as conn:\n",
    "    for tbl in (\"dim_age_group\",\"dim_gender\",\"dim_degree\",\"dim_department\",\"dim_family_income\",\"dim_platform\",\"dim_relationship\",\"dim_academic_level\"):\n",
    "        n = conn.execute(text(f\"SELECT COUNT(*) FROM `{tbl}`\")).scalar()\n",
    "        print(f\"{tbl}: {n} rows\")\n",
    "\n",
    "print(\"Dimension load complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d44c2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = {\n",
    "    \"dim_age_group\": dim_age_group,\n",
    "    \"dim_gender\": dim_gender,\n",
    "    \"dim_degree\": dim_degree,\n",
    "    \"dim_department\": dim_department,\n",
    "    \"dim_family_income\": dim_family_income,\n",
    "    \"dim_platform\": dim_platform,\n",
    "    \"dim_relationship\": dim_relationship,\n",
    "    \"dim_academic_level\": dim_academic_level,\n",
    "}\n",
    "\n",
    "for name, df in dims.items():\n",
    "    df.to_csv(f\"{name}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
